{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration for code:\n",
    "\n",
    "- https://developers.google.com/machine-learning/guides/text-classification/\n",
    "- https://github.com/google/eng-edu/blob/master/ml/guides/text_classification/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload\n",
    "\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yulia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "from helpers import explore_data\n",
    "from helpers import preprocess_data\n",
    "from helpers import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/home/yulia/W266-Final-Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecdata_path = main_dir+'Classification/data/vectorized/ethnicity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = scipy.sparse.load_npz(os.path.join(vecdata_path, 'train_vec.npz'))\n",
    "val_vec = scipy.sparse.load_npz(os.path.join(vecdata_path, 'val_vec.npz'))\n",
    "test_vec = scipy.sparse.load_npz(os.path.join(vecdata_path, 'test_vec.npz'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((188520, 10000), (62840, 10000), (62840, 10000))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec.shape, val_vec.shape, test_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir+'Classification/data/splits/ethnicity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'train_list'), 'rb') as fp:\n",
    "    train = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'train_ids'), 'rb') as fp:\n",
    "    train_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'train_target'), 'rb') as fp:\n",
    "    train_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_list'), 'rb') as fp:\n",
    "    val = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_ids'), 'rb') as fp:\n",
    "    val_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_target'), 'rb') as fp:\n",
    "    val_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_list'), 'rb') as fp:\n",
    "    test = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_ids'), 'rb') as fp:\n",
    "    test_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_target'), 'rb') as fp:\n",
    "    test_target = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94260, 31420, 31420)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_target), sum(val_target), sum(test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model: Multi-Layer Perceptron (Vanilla NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = main_dir + 'Classification/logs/Ethnicity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_model_params = {\n",
    "    'model_type': 'mlp',\n",
    "    'learning_rate': 0.001,\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 128,\n",
    "    'layers': 2,\n",
    "    'units': 64,\n",
    "    'dropout_rate': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Train on 188520 samples, validate on 62840 samples\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1000\n",
      " - 29s - loss: 0.5523 - acc: 0.7160 - val_loss: 0.5168 - val_acc: 0.7404\n",
      "Epoch 2/1000\n",
      " - 28s - loss: 0.5099 - acc: 0.7431 - val_loss: 0.5090 - val_acc: 0.7438\n",
      "Epoch 3/1000\n",
      " - 29s - loss: 0.4955 - acc: 0.7519 - val_loss: 0.5051 - val_acc: 0.7471\n",
      "Epoch 4/1000\n",
      " - 28s - loss: 0.4849 - acc: 0.7591 - val_loss: 0.5030 - val_acc: 0.7476\n",
      "Epoch 5/1000\n",
      " - 28s - loss: 0.4738 - acc: 0.7673 - val_loss: 0.5004 - val_acc: 0.7519\n",
      "Epoch 6/1000\n",
      " - 28s - loss: 0.4642 - acc: 0.7745 - val_loss: 0.4983 - val_acc: 0.7549\n",
      "Epoch 7/1000\n",
      " - 29s - loss: 0.4521 - acc: 0.7823 - val_loss: 0.4996 - val_acc: 0.7549\n",
      "Epoch 8/1000\n",
      " - 25s - loss: 0.4394 - acc: 0.7897 - val_loss: 0.4981 - val_acc: 0.7561\n",
      "Epoch 9/1000\n",
      " - 28s - loss: 0.4281 - acc: 0.7981 - val_loss: 0.4994 - val_acc: 0.7574\n",
      "Epoch 10/1000\n",
      " - 28s - loss: 0.4143 - acc: 0.8069 - val_loss: 0.5007 - val_acc: 0.7552\n",
      "Validation accuracy: 0.755219578742981, loss: 0.5007450655871026\n"
     ]
    }
   ],
   "source": [
    "reload(train_model)\n",
    "history, model, train_pred_probs, val_pred_probs = train_model.train_model(((train_vec, train_target), (val_vec, val_target)), logs_base_dir, **ngram_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score/save test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = main_dir + 'Classification/model/ethnicity/'\n",
    "model.save(model_dir+'mlp_ngram_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62840/62840 [==============================] - 4s 61us/sample - loss: 0.5041 - acc: 0.7516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5040547801536182, 0.7515913]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_probs = model.predict(test_vec)\n",
    "model.evaluate(test_vec, test_target, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_path = main_dir+'Classification/data/probs/ethnicity/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_mlp_ngram', val_pred_probs, allow_pickle=True, fix_imports=True)\n",
    "np.save(probs_path+'test_pred_probs_mlp_ngram', test_pred_probs, allow_pickle=True, fix_imports=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
