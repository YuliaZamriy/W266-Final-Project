{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration for code:\n",
    "\n",
    "- https://developers.google.com/machine-learning/guides/text-classification/\n",
    "- https://github.com/google/eng-edu/blob/master/ml/guides/text_classification/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yulia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "from helpers import explore_data\n",
    "from helpers import preprocess_data\n",
    "from helpers import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0-rc2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/home/yulia/W266-Final-Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_path = main_dir+'Classification/data/tokenized/age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.load(os.path.join(token_path, 'train_vec.npy'))\n",
    "val_vec = np.load(os.path.join(token_path, 'val_vec.npy'))\n",
    "test_vec = np.load(os.path.join(token_path, 'test_vec.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = pickle.load(open(os.path.join(token_path, 'word_index.p'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229048, 76348, 76352)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vec), len(val_vec), len(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir+'Classification/data/splits/age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'train_target'), 'rb') as fp:\n",
    "    train_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_target'), 'rb') as fp:\n",
    "    val_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_target'), 'rb') as fp:\n",
    "    test_target = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(114524, 38174, 38176)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_target), sum(val_target), sum(test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model - Full Speech + Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = main_dir + 'Classification/logs/age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_params = {\n",
    "    'model_type': 'cnn',\n",
    "    'word_index': word_index,\n",
    "    'learning_rate': 0.001,\n",
    "    'layers': 2,\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 128,\n",
    "    'filters': 64,\n",
    "    'dropout_rate': 0.2,\n",
    "    'embedding_dim': 200,\n",
    "    'kernel_size': 5,\n",
    "    'pool_size': 1,\n",
    "    'max_num_words': 20000,\n",
    "    'use_pretrained_embedding': True,\n",
    "    'is_embedding_trainable': True,\n",
    "    'glove_dir': main_dir + 'data'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "It took 33.6 seconds\n",
      "Preparing embedding matrix.\n",
      "Embedding matrix has been built.\n",
      "Its shape is (20000, 200).\n",
      "It took 0.1 seconds\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 229048 samples, validate on 76348 samples\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/1000\n",
      " - 2617s - loss: 0.6650 - acc: 0.6026 - val_loss: 0.6506 - val_acc: 0.6218\n",
      "Epoch 2/1000\n",
      " - 2593s - loss: 0.6459 - acc: 0.6246 - val_loss: 0.6395 - val_acc: 0.6325\n",
      "Epoch 3/1000\n",
      " - 2346s - loss: 0.6312 - acc: 0.6416 - val_loss: 0.6458 - val_acc: 0.6221\n",
      "Epoch 4/1000\n",
      " - 1508s - loss: 0.6151 - acc: 0.6594 - val_loss: 0.6361 - val_acc: 0.6360\n",
      "Epoch 5/1000\n",
      " - 1506s - loss: 0.5966 - acc: 0.6779 - val_loss: 0.6390 - val_acc: 0.6314\n",
      "Epoch 6/1000\n",
      " - 1505s - loss: 0.5758 - acc: 0.6963 - val_loss: 0.6426 - val_acc: 0.6300\n",
      "Validation accuracy: 0.6299968361854553, loss: 0.6426306310991348\n"
     ]
    }
   ],
   "source": [
    "reload(train_model)\n",
    "history, model, train_pred_probs, val_pred_probs = train_model.train_model(((train_vec, train_target), (val_vec, val_target)), logs_base_dir, **cnn_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score/save test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = main_dir + 'Classification/model/age/'\n",
    "model.save(model_dir+'cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76352/76352 [==============================] - 122s 2ms/sample - loss: 0.6460 - acc: 0.6269\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.645956449316813, 0.6268598]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_probs = model.predict(test_vec)\n",
    "model.evaluate(test_vec, test_target, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_path = main_dir+'Classification/data/probs/age/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn', val_pred_probs, allow_pickle=True, fix_imports=True)\n",
    "np.save(probs_path+'test_pred_probs_cnn', test_pred_probs, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN - chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir+'Classification/data/splits/age'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'train_list'), 'rb') as fp:\n",
    "    train = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'train_ids'), 'rb') as fp:\n",
    "    train_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_list'), 'rb') as fp:\n",
    "    val = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_ids'), 'rb') as fp:\n",
    "    val_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_list'), 'rb') as fp:\n",
    "    test = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_ids'), 'rb') as fp:\n",
    "    test_ids = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has 229048 speeches\n",
      "It was split into 1852321 chunks\n",
      "Checks on ids and target 1852321 1852321\n",
      "Original target mean 0.5\n",
      "New target mean 0.4941962003346072\n",
      "Original data has 76348 speeches\n",
      "It was split into 617897 chunks\n",
      "Checks on ids and target 617897 617897\n",
      "Original target mean 0.5\n",
      "New target mean 0.49627850596458634\n",
      "Original data has 76352 speeches\n",
      "It was split into 610677 chunks\n",
      "Checks on ids and target 610677 610677\n",
      "Original target mean 0.5\n",
      "New target mean 0.4935931760980027\n",
      "\n",
      "It took 16.3 seconds to create the dictionary\n"
     ]
    }
   ],
   "source": [
    "reload(preprocess_data)\n",
    "start_time = time.time()\n",
    "train_chunk, train_ids_chunk, train_target_chunk = preprocess_data.split_speech_to_chunks(train, train_ids, train_target, max_len=chunk_len)\n",
    "val_chunk, val_ids_chunk, val_target_chunk = preprocess_data.split_speech_to_chunks(val, val_ids, val_target, max_len=chunk_len)\n",
    "test_chunk, test_ids_chunk, test_target_chunk = preprocess_data.split_speech_to_chunks(test, test_ids, test_target, max_len=chunk_len)\n",
    "print(\"\\nIt took {:.1f} seconds to create the dictionary\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'val_ids_chunk'), 'wb') as fp:\n",
    "    pickle.dump(val_ids_chunk, fp)\n",
    "with open(os.path.join(outdata_path, 'test_ids_chunk'), 'wb') as fp:\n",
    "    pickle.dump(val_ids_chunk, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.load(os.path.join(token_path, 'train_vec_chunk.npy'))\n",
    "val_vec = np.load(os.path.join(token_path, 'val_vec_chunk.npy'))\n",
    "test_vec = np.load(os.path.join(token_path, 'test_vec_chunk.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "It took 19.6 seconds\n",
      "Preparing embedding matrix.\n",
      "Embedding matrix has been built.\n",
      "Its shape is (20000, 200).\n",
      "It took 0.1 seconds\n",
      "Train on 1852321 samples, validate on 617897 samples\n",
      "Epoch 1/1000\n",
      " - 1026s - loss: 0.6774 - acc: 0.5674 - val_loss: 0.6752 - val_acc: 0.5762\n",
      "Epoch 2/1000\n",
      " - 1021s - loss: 0.6660 - acc: 0.5906 - val_loss: 0.6732 - val_acc: 0.5785\n",
      "Epoch 3/1000\n",
      " - 1022s - loss: 0.6595 - acc: 0.6015 - val_loss: 0.6748 - val_acc: 0.5752\n",
      "Epoch 4/1000\n",
      " - 1023s - loss: 0.6532 - acc: 0.6107 - val_loss: 0.6735 - val_acc: 0.5774\n",
      "Validation accuracy: 0.5774489641189575, loss: 0.6734820482685516\n"
     ]
    }
   ],
   "source": [
    "history_chunk, model, train_pred_probs_chunk, val_pred_probs_chunk = train_model.train_model(((train_vec, train_target_chunk), (val_vec, val_target_chunk)), logs_base_dir, **cnn_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir+'cnn_chunk_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610677/610677 [==============================] - 62s 102us/sample - loss: 0.6728 - acc: 0.5789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6727688433602681, 0.5788854]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_probs_chunk = model.predict(test_vec)\n",
    "model.evaluate(test_vec, test_target_chunk, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn_chunk', val_pred_probs_chunk, allow_pickle=True, fix_imports=True)\n",
    "np.save(probs_path+'test_pred_probs_cnn_chunk', test_pred_probs_chunk, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000059</td>\n",
       "      <td>0.424837</td>\n",
       "      <td>0.678766</td>\n",
       "      <td>0.574726</td>\n",
       "      <td>0</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000124</td>\n",
       "      <td>0.412168</td>\n",
       "      <td>0.576660</td>\n",
       "      <td>0.497430</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000354</td>\n",
       "      <td>0.389553</td>\n",
       "      <td>0.547641</td>\n",
       "      <td>0.473952</td>\n",
       "      <td>1</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000360</td>\n",
       "      <td>0.053266</td>\n",
       "      <td>0.663706</td>\n",
       "      <td>0.410312</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000452</td>\n",
       "      <td>0.432352</td>\n",
       "      <td>0.537042</td>\n",
       "      <td>0.484697</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids  probs_min  probs_max  probs_mean  target     preds  \\\n",
       "0  1000000059   0.424837   0.678766    0.574726       0  0.888889   \n",
       "1  1000000124   0.412168   0.576660    0.497430       1  0.666667   \n",
       "2  1000000354   0.389553   0.547641    0.473952       1  0.250000   \n",
       "3  1000000360   0.053266   0.663706    0.410312       0  0.166667   \n",
       "4  1000000452   0.432352   0.537042    0.484697       0  0.500000   \n",
       "\n",
       "   preds_probs_mean  preds_mean  \n",
       "0                 1           1  \n",
       "1                 0           1  \n",
       "2                 0           0  \n",
       "3                 0           0  \n",
       "4                 0           0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds_chunk = val_pred_probs_chunk > 0.5\n",
    "pred_df = pd.DataFrame({'ids': val_ids_chunk, 'target': val_target_chunk, 'probs': val_pred_probs_chunk.flatten(), 'preds': val_preds_chunk.flatten()})\n",
    "f = {'probs': [min, max, 'mean']}\n",
    "pred_aggr_df = pred_df.groupby('ids').agg(f).reset_index()\n",
    "pred_aggr_df.columns = ['ids', 'probs_min', 'probs_max', 'probs_mean']\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['target', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['preds', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df['preds_probs_mean'] = pred_aggr_df['probs_mean'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df['preds_mean'] = pred_aggr_df['preds'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_orig</th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1060162543</td>\n",
       "      <td>0.585735</td>\n",
       "      <td>0.632199</td>\n",
       "      <td>0.608967</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>980236360</td>\n",
       "      <td>0.437220</td>\n",
       "      <td>0.902704</td>\n",
       "      <td>0.576761</td>\n",
       "      <td>1</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>990257551</td>\n",
       "      <td>0.288472</td>\n",
       "      <td>0.488631</td>\n",
       "      <td>0.421584</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1010233637</td>\n",
       "      <td>0.384151</td>\n",
       "      <td>0.646413</td>\n",
       "      <td>0.544882</td>\n",
       "      <td>1</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>980084907</td>\n",
       "      <td>0.332441</td>\n",
       "      <td>0.546510</td>\n",
       "      <td>0.435048</td>\n",
       "      <td>1</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_orig         ids  probs_min  probs_max  probs_mean  target  \\\n",
       "0            1  1060162543   0.585735   0.632199    0.608967       1   \n",
       "1            1   980236360   0.437220   0.902704    0.576761       1   \n",
       "2            1   990257551   0.288472   0.488631    0.421584       1   \n",
       "3            1  1010233637   0.384151   0.646413    0.544882       1   \n",
       "4            1   980084907   0.332441   0.546510    0.435048       1   \n",
       "\n",
       "      preds  preds_probs_mean  preds_mean  \n",
       "0  1.000000                 1           1  \n",
       "1  0.739130                 1           1  \n",
       "2  0.000000                 0           0  \n",
       "3  0.785714                 1           1  \n",
       "4  0.095238                 0           0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.DataFrame({'target_orig': val_target, 'ids': val_ids})\n",
    "original_df = original_df.merge(pred_aggr_df, on=\"ids\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_aggr_chunk = original_df.preds_probs_mean\n",
    "val_pred_probs_aggr_chunk = original_df.probs_mean\n",
    "# val_aggr_target = pred_aggr_df.target\n",
    "# val_aggr_ids = pred_aggr_df.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn_aggr_chunk', val_pred_probs_aggr_chunk, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000050</td>\n",
       "      <td>0.419159</td>\n",
       "      <td>0.601839</td>\n",
       "      <td>0.519711</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000123</td>\n",
       "      <td>0.401327</td>\n",
       "      <td>0.571910</td>\n",
       "      <td>0.465891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000319</td>\n",
       "      <td>0.167810</td>\n",
       "      <td>0.603652</td>\n",
       "      <td>0.386948</td>\n",
       "      <td>0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000371</td>\n",
       "      <td>0.206099</td>\n",
       "      <td>0.381643</td>\n",
       "      <td>0.315433</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000377</td>\n",
       "      <td>0.315352</td>\n",
       "      <td>0.412466</td>\n",
       "      <td>0.353144</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids  probs_min  probs_max  probs_mean  target     preds  \\\n",
       "0  1000000050   0.419159   0.601839    0.519711       1  0.600000   \n",
       "1  1000000123   0.401327   0.571910    0.465891       1  0.200000   \n",
       "2  1000000319   0.167810   0.603652    0.386948       0  0.111111   \n",
       "3  1000000371   0.206099   0.381643    0.315433       0  0.000000   \n",
       "4  1000000377   0.315352   0.412466    0.353144       0  0.000000   \n",
       "\n",
       "   preds_probs_mean  preds_mean  \n",
       "0                 1           1  \n",
       "1                 0           0  \n",
       "2                 0           0  \n",
       "3                 0           0  \n",
       "4                 0           0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_chunk = test_pred_probs_chunk > 0.5\n",
    "pred_df = pd.DataFrame({'ids': test_ids_chunk, 'target': test_target_chunk, 'probs': test_pred_probs_chunk.flatten(), 'preds': test_preds_chunk.flatten()})\n",
    "f = {'probs': [min, max, 'mean']}\n",
    "pred_aggr_df = pred_df.groupby('ids').agg(f).reset_index()\n",
    "pred_aggr_df.columns = ['ids', 'probs_min', 'probs_max', 'probs_mean']\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['target', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['preds', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df['preds_probs_mean'] = pred_aggr_df['probs_mean'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df['preds_mean'] = pred_aggr_df['preds'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_orig</th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1050182087</td>\n",
       "      <td>0.415216</td>\n",
       "      <td>0.591632</td>\n",
       "      <td>0.510988</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1020096707</td>\n",
       "      <td>0.365078</td>\n",
       "      <td>0.645605</td>\n",
       "      <td>0.553838</td>\n",
       "      <td>1</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1120051071</td>\n",
       "      <td>0.562652</td>\n",
       "      <td>0.576362</td>\n",
       "      <td>0.569507</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>970125650</td>\n",
       "      <td>0.478606</td>\n",
       "      <td>0.556128</td>\n",
       "      <td>0.517367</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>980064867</td>\n",
       "      <td>0.459898</td>\n",
       "      <td>0.644666</td>\n",
       "      <td>0.578491</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_orig         ids  probs_min  probs_max  probs_mean  target  \\\n",
       "0            1  1050182087   0.415216   0.591632    0.510988       1   \n",
       "1            1  1020096707   0.365078   0.645605    0.553838       1   \n",
       "2            1  1120051071   0.562652   0.576362    0.569507       1   \n",
       "3            1   970125650   0.478606   0.556128    0.517367       1   \n",
       "4            1   980064867   0.459898   0.644666    0.578491       1   \n",
       "\n",
       "      preds  preds_probs_mean  preds_mean  \n",
       "0  0.500000                 1           0  \n",
       "1  0.727273                 1           1  \n",
       "2  1.000000                 1           1  \n",
       "3  0.500000                 1           0  \n",
       "4  0.800000                 1           1  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.DataFrame({'target_orig': test_target, 'ids': test_ids})\n",
    "original_df = original_df.merge(pred_aggr_df, on=\"ids\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_aggr_chunk = original_df.preds_probs_mean\n",
    "test_pred_probs_aggr_chunk = original_df.probs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'test_pred_probs_cnn_aggr_chunk', test_pred_probs_aggr_chunk, allow_pickle=True, fix_imports=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
