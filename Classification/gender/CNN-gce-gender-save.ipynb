{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration for code:\n",
    "\n",
    "- https://developers.google.com/machine-learning/guides/text-classification/\n",
    "- https://github.com/google/eng-edu/blob/master/ml/guides/text_classification/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yulia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "from helpers import explore_data\n",
    "from helpers import preprocess_data\n",
    "from helpers import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0-rc2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/home/yulia/W266-Final-Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_path = main_dir+'Classification/data/tokenized/gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.load(os.path.join(token_path, 'train_vec.npy'))\n",
    "val_vec = np.load(os.path.join(token_path, 'val_vec.npy'))\n",
    "test_vec = np.load(os.path.join(token_path, 'test_vec.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = pickle.load(open(os.path.join(token_path, 'word_index.p'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188148, 62716, 62716)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vec), len(val_vec), len(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir+'Classification/data/splits/gender/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'train_target'), 'rb') as fp:\n",
    "    train_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_target'), 'rb') as fp:\n",
    "    val_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_target'), 'rb') as fp:\n",
    "    test_target = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(94074, 31358, 31358)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_target), sum(val_target), sum(test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model - Full Speech + Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = main_dir + 'Classification/logs/gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_params = {\n",
    "    'model_type': 'cnn',\n",
    "    'word_index': word_index,\n",
    "    'learning_rate': 0.001,\n",
    "    'layers': 2,\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 128,\n",
    "    'filters': 64,\n",
    "    'dropout_rate': 0.2,\n",
    "    'embedding_dim': 200,\n",
    "    'kernel_size': 5,\n",
    "    'pool_size': 1,\n",
    "    'max_num_words': 20000,\n",
    "    'use_pretrained_embedding': True,\n",
    "    'is_embedding_trainable': True,\n",
    "    'glove_dir': main_dir + 'data'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "It took 36.4 seconds\n",
      "Preparing embedding matrix.\n",
      "Embedding matrix has been built.\n",
      "Its shape is (20000, 200).\n",
      "It took 0.2 seconds\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 188148 samples, validate on 62716 samples\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /home/yulia/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/1000\n",
      " - 2018s - loss: 0.5992 - acc: 0.6750 - val_loss: 0.5543 - val_acc: 0.7175\n",
      "Epoch 2/1000\n",
      " - 2007s - loss: 0.5468 - acc: 0.7220 - val_loss: 0.5385 - val_acc: 0.7333\n",
      "Epoch 3/1000\n",
      " - 2004s - loss: 0.5216 - acc: 0.7402 - val_loss: 0.5256 - val_acc: 0.7375\n",
      "Epoch 4/1000\n",
      " - 1482s - loss: 0.5015 - acc: 0.7546 - val_loss: 0.5251 - val_acc: 0.7386\n",
      "Epoch 5/1000\n",
      " - 1370s - loss: 0.4832 - acc: 0.7675 - val_loss: 0.5242 - val_acc: 0.7389\n",
      "Epoch 6/1000\n",
      " - 2126s - loss: 0.4657 - acc: 0.7785 - val_loss: 0.5217 - val_acc: 0.7390\n",
      "Epoch 7/1000\n",
      " - 2134s - loss: 0.4466 - acc: 0.7900 - val_loss: 0.5258 - val_acc: 0.7364\n",
      "Epoch 8/1000\n",
      " - 2134s - loss: 0.4280 - acc: 0.8007 - val_loss: 0.5345 - val_acc: 0.7354\n",
      "Validation accuracy: 0.7354263663291931, loss: 0.5344531932718953\n"
     ]
    }
   ],
   "source": [
    "reload(train_model)\n",
    "history, model, train_pred_probs, val_pred_probs = train_model.train_model(((train_vec, train_target), (val_vec, val_target)), logs_base_dir, **cnn_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score/save test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = main_dir + 'Classification/model/gender/'\n",
    "model.save(model_dir+'cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62716/62716 [==============================] - 95s 2ms/sample - loss: 0.5418 - acc: 0.7318\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.541759143299013, 0.73182285]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_probs = model.predict(test_vec)\n",
    "model.evaluate(test_vec, test_target, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_path = main_dir+'Classification/data/probs/gender/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn', val_pred_probs, allow_pickle=True, fix_imports=True)\n",
    "np.save(probs_path+'test_pred_probs_cnn', test_pred_probs, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN - chunking the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir+'Classification/data/splits/gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'train_list'), 'rb') as fp:\n",
    "    train = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'train_ids'), 'rb') as fp:\n",
    "    train_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_list'), 'rb') as fp:\n",
    "    val = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_ids'), 'rb') as fp:\n",
    "    val_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_list'), 'rb') as fp:\n",
    "    test = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_ids'), 'rb') as fp:\n",
    "    test_ids = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has 188148 speeches\n",
      "It was split into 1557233 chunks\n",
      "Checks on ids and target 1557233 1557233\n",
      "Original target mean 0.5\n",
      "New target mean 0.5144747125189358\n",
      "Original data has 62716 speeches\n",
      "It was split into 521540 chunks\n",
      "Checks on ids and target 521540 521540\n",
      "Original target mean 0.5\n",
      "New target mean 0.5181059937876289\n",
      "Original data has 62716 speeches\n",
      "It was split into 522421 chunks\n",
      "Checks on ids and target 522421 522421\n",
      "Original target mean 0.5\n",
      "New target mean 0.5162503038736957\n",
      "\n",
      "It took 13.3 seconds to chunk the data\n"
     ]
    }
   ],
   "source": [
    "reload(preprocess_data)\n",
    "start_time = time.time()\n",
    "train_chunk, train_ids_chunk, train_target_chunk = preprocess_data.split_speech_to_chunks(train, train_ids, train_target, max_len=chunk_len)\n",
    "val_chunk, val_ids_chunk, val_target_chunk = preprocess_data.split_speech_to_chunks(val, val_ids, val_target, max_len=chunk_len)\n",
    "test_chunk, test_ids_chunk, test_target_chunk = preprocess_data.split_speech_to_chunks(test, test_ids, test_target, max_len=chunk_len)\n",
    "print(\"\\nIt took {:.1f} seconds to chunk the data\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'val_ids_chunk'), 'wb') as fp:\n",
    "    pickle.dump(val_ids_chunk, fp)\n",
    "with open(os.path.join(outdata_path, 'test_ids_chunk'), 'wb') as fp:\n",
    "    pickle.dump(val_ids_chunk, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.load(os.path.join(token_path, 'train_vec_chunk.npy'))\n",
    "val_vec = np.load(os.path.join(token_path, 'val_vec_chunk.npy'))\n",
    "test_vec = np.load(os.path.join(token_path, 'test_vec_chunk.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "It took 20.6 seconds\n",
      "Preparing embedding matrix.\n",
      "Embedding matrix has been built.\n",
      "Its shape is (20000, 200).\n",
      "It took 0.1 seconds\n",
      "Train on 1557233 samples, validate on 521540 samples\n",
      "Epoch 1/1000\n",
      " - 1102s - loss: 0.6188 - acc: 0.6545 - val_loss: 0.6084 - val_acc: 0.6707\n",
      "Epoch 2/1000\n",
      " - 1511s - loss: 0.5978 - acc: 0.6761 - val_loss: 0.6100 - val_acc: 0.6718\n",
      "Epoch 3/1000\n",
      " - 1515s - loss: 0.5884 - acc: 0.6846 - val_loss: 0.6024 - val_acc: 0.6747\n",
      "Epoch 4/1000\n",
      " - 1503s - loss: 0.5791 - acc: 0.6933 - val_loss: 0.6009 - val_acc: 0.6755\n",
      "Epoch 5/1000\n",
      " - 1514s - loss: 0.5697 - acc: 0.7007 - val_loss: 0.6017 - val_acc: 0.6734\n",
      "Epoch 6/1000\n",
      " - 1511s - loss: 0.5606 - acc: 0.7081 - val_loss: 0.6009 - val_acc: 0.6754\n",
      "Validation accuracy: 0.6754150986671448, loss: 0.6009258436663877\n"
     ]
    }
   ],
   "source": [
    "history_chunk, model, train_pred_probs_chunk, val_pred_probs_chunk = train_model.train_model(((train_vec, train_target_chunk), (val_vec, val_target_chunk)), logs_base_dir, **cnn_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir+'cnn_chunk_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522421/522421 [==============================] - 98s 187us/sample - loss: 0.6053 - acc: 0.6713\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6053227365919072, 0.6713187]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_probs_chunk = model.predict(test_vec)\n",
    "model.evaluate(test_vec, test_target_chunk, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn_chunk', val_pred_probs_chunk, allow_pickle=True, fix_imports=True)\n",
    "np.save(probs_path+'test_pred_probs_cnn_chunk', test_pred_probs_chunk, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000354</td>\n",
       "      <td>0.225319</td>\n",
       "      <td>0.572533</td>\n",
       "      <td>0.361126</td>\n",
       "      <td>0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000454</td>\n",
       "      <td>0.353985</td>\n",
       "      <td>0.353985</td>\n",
       "      <td>0.353985</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000541</td>\n",
       "      <td>0.105641</td>\n",
       "      <td>0.542725</td>\n",
       "      <td>0.293641</td>\n",
       "      <td>0</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000727</td>\n",
       "      <td>0.332692</td>\n",
       "      <td>0.719526</td>\n",
       "      <td>0.429663</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000738</td>\n",
       "      <td>0.208273</td>\n",
       "      <td>0.472101</td>\n",
       "      <td>0.326049</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids  probs_min  probs_max  probs_mean  target     preds  \\\n",
       "0  1000000354   0.225319   0.572533    0.361126       0  0.083333   \n",
       "1  1000000454   0.353985   0.353985    0.353985       0  0.000000   \n",
       "2  1000000541   0.105641   0.542725    0.293641       0  0.037037   \n",
       "3  1000000727   0.332692   0.719526    0.429663       0  0.142857   \n",
       "4  1000000738   0.208273   0.472101    0.326049       0  0.000000   \n",
       "\n",
       "   preds_probs_mean  preds_mean  \n",
       "0                 0           0  \n",
       "1                 0           0  \n",
       "2                 0           0  \n",
       "3                 0           0  \n",
       "4                 0           0  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds_chunk = val_pred_probs_chunk > 0.5\n",
    "pred_df = pd.DataFrame({'ids': val_ids_chunk, 'target': val_target_chunk, 'probs': val_pred_probs_chunk.flatten(), 'preds': val_preds_chunk.flatten()})\n",
    "f = {'probs': [min, max, 'mean']}\n",
    "pred_aggr_df = pred_df.groupby('ids').agg(f).reset_index()\n",
    "pred_aggr_df.columns = ['ids', 'probs_min', 'probs_max', 'probs_mean']\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['target', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['preds', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df['preds_probs_mean'] = pred_aggr_df['probs_mean'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df['preds_mean'] = pred_aggr_df['preds'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_orig</th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1090179235</td>\n",
       "      <td>0.523424</td>\n",
       "      <td>0.705958</td>\n",
       "      <td>0.577375</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1090044795</td>\n",
       "      <td>0.454025</td>\n",
       "      <td>0.615893</td>\n",
       "      <td>0.542140</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1020046081</td>\n",
       "      <td>0.525251</td>\n",
       "      <td>0.915206</td>\n",
       "      <td>0.773324</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1090124860</td>\n",
       "      <td>0.494615</td>\n",
       "      <td>0.829627</td>\n",
       "      <td>0.627593</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1140096300</td>\n",
       "      <td>0.324812</td>\n",
       "      <td>0.694769</td>\n",
       "      <td>0.527163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_orig         ids  probs_min  probs_max  probs_mean  target  \\\n",
       "0            1  1090179235   0.523424   0.705958    0.577375       1   \n",
       "1            1  1090044795   0.454025   0.615893    0.542140       1   \n",
       "2            1  1020046081   0.525251   0.915206    0.773324       1   \n",
       "3            1  1090124860   0.494615   0.829627    0.627593       1   \n",
       "4            1  1140096300   0.324812   0.694769    0.527163       1   \n",
       "\n",
       "      preds  preds_probs_mean  preds_mean  \n",
       "0  1.000000                 1           1  \n",
       "1  0.666667                 1           1  \n",
       "2  1.000000                 1           1  \n",
       "3  0.833333                 1           1  \n",
       "4  0.600000                 1           1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.DataFrame({'target_orig': val_target, 'ids': val_ids})\n",
    "original_df = original_df.merge(pred_aggr_df, on=\"ids\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31358, 31358)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df.target_orig.sum(), original_df.target.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_aggr_chunk = original_df.preds_probs_mean\n",
    "val_pred_probs_aggr_chunk = original_df.probs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn_aggr_chunk', val_pred_probs_aggr_chunk, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000059</td>\n",
       "      <td>0.259346</td>\n",
       "      <td>0.746913</td>\n",
       "      <td>0.498017</td>\n",
       "      <td>1</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000168</td>\n",
       "      <td>0.436655</td>\n",
       "      <td>0.620963</td>\n",
       "      <td>0.539030</td>\n",
       "      <td>0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000353</td>\n",
       "      <td>0.175305</td>\n",
       "      <td>0.626415</td>\n",
       "      <td>0.392085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000358</td>\n",
       "      <td>0.102935</td>\n",
       "      <td>0.503076</td>\n",
       "      <td>0.303005</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000752</td>\n",
       "      <td>0.173370</td>\n",
       "      <td>0.173370</td>\n",
       "      <td>0.173370</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids  probs_min  probs_max  probs_mean  target     preds  \\\n",
       "0  1000000059   0.259346   0.746913    0.498017       1  0.555556   \n",
       "1  1000000168   0.436655   0.620963    0.539030       0  0.750000   \n",
       "2  1000000353   0.175305   0.626415    0.392085       0  0.307692   \n",
       "3  1000000358   0.102935   0.503076    0.303005       0  0.500000   \n",
       "4  1000000752   0.173370   0.173370    0.173370       0  0.000000   \n",
       "\n",
       "   preds_probs_mean  preds_mean  \n",
       "0                 0           1  \n",
       "1                 1           1  \n",
       "2                 0           0  \n",
       "3                 0           0  \n",
       "4                 0           0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_chunk = test_pred_probs_chunk > 0.5\n",
    "pred_df = pd.DataFrame({'ids': test_ids_chunk, 'target': test_target_chunk, 'probs': test_pred_probs_chunk.flatten(), 'preds': test_preds_chunk.flatten()})\n",
    "f = {'probs': [min, max, 'mean']}\n",
    "pred_aggr_df = pred_df.groupby('ids').agg(f).reset_index()\n",
    "pred_aggr_df.columns = ['ids', 'probs_min', 'probs_max', 'probs_mean']\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['target', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['preds', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df['preds_probs_mean'] = pred_aggr_df['probs_mean'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df['preds_mean'] = pred_aggr_df['preds'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_orig</th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1070082863</td>\n",
       "      <td>0.305813</td>\n",
       "      <td>0.413437</td>\n",
       "      <td>0.343526</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1020062705</td>\n",
       "      <td>0.098636</td>\n",
       "      <td>0.710984</td>\n",
       "      <td>0.461758</td>\n",
       "      <td>1</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1060179537</td>\n",
       "      <td>0.421645</td>\n",
       "      <td>0.988484</td>\n",
       "      <td>0.665958</td>\n",
       "      <td>1</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1130064416</td>\n",
       "      <td>0.600023</td>\n",
       "      <td>0.941471</td>\n",
       "      <td>0.761403</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1020001636</td>\n",
       "      <td>0.361922</td>\n",
       "      <td>0.630311</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_orig         ids  probs_min  probs_max  probs_mean  target  \\\n",
       "0            1  1070082863   0.305813   0.413437    0.343526       1   \n",
       "1            1  1020062705   0.098636   0.710984    0.461758       1   \n",
       "2            1  1060179537   0.421645   0.988484    0.665958       1   \n",
       "3            1  1130064416   0.600023   0.941471    0.761403       1   \n",
       "4            1  1020001636   0.361922   0.630311    0.527600       1   \n",
       "\n",
       "      preds  preds_probs_mean  preds_mean  \n",
       "0  0.000000                 0           0  \n",
       "1  0.392857                 0           0  \n",
       "2  0.545455                 1           1  \n",
       "3  1.000000                 1           1  \n",
       "4  0.666667                 1           1  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.DataFrame({'target_orig': test_target, 'ids': test_ids})\n",
    "original_df = original_df.merge(pred_aggr_df, on=\"ids\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_aggr_chunk = original_df.preds_probs_mean\n",
    "test_pred_probs_aggr_chunk = original_df.probs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'test_pred_probs_cnn_aggr_chunk', test_pred_probs_aggr_chunk, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
