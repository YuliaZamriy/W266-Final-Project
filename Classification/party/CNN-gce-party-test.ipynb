{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration for code:\n",
    "\n",
    "- https://developers.google.com/machine-learning/guides/text-classification/\n",
    "- https://github.com/google/eng-edu/blob/master/ml/guides/text_classification/load_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yulia/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "from helpers import explore_data\n",
    "from helpers import preprocess_data\n",
    "from helpers import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.0-rc2'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/home/yulia/W266-Final-Project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_path = main_dir+'Classification/data/tokenized/party'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.load(os.path.join(token_path, 'train_vec.npy'))\n",
    "val_vec = np.load(os.path.join(token_path, 'val_vec.npy'))\n",
    "test_vec = np.load(os.path.join(token_path, 'test_vec.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = pickle.load(open(os.path.join(token_path, 'word_index.p'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303459, 101153, 101154)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_vec), len(val_vec), len(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir+'Classification/data/splits/party'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'train_target'), 'rb') as fp:\n",
    "    train_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_target'), 'rb') as fp:\n",
    "    val_target = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_target'), 'rb') as fp:\n",
    "    test_target = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(161472, 53824, 53825)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_target), sum(val_target), sum(test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN model - Full Speech + Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = main_dir + 'Classification/logs/party'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model_params = {\n",
    "    'model_type': 'cnn',\n",
    "    'word_index': word_index,\n",
    "    'learning_rate': 0.001,\n",
    "    'layers': 2,\n",
    "    'epochs': 1000,\n",
    "    'batch_size': 128,\n",
    "    'filters': 64,\n",
    "    'dropout_rate': 0.2,\n",
    "    'embedding_dim': 200,\n",
    "    'kernel_size': 5,\n",
    "    'pool_size': 1,\n",
    "    'max_num_words': 20000,\n",
    "    'use_pretrained_embedding': True,\n",
    "    'is_embedding_trainable': True,\n",
    "    'glove_dir': main_dir + 'data'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "It took 33.6 seconds\n",
      "Preparing embedding matrix.\n",
      "Embedding matrix has been built.\n",
      "Its shape is (20000, 200).\n",
      "It took 0.1 seconds\n",
      "Train on 303459 samples, validate on 101153 samples\n",
      "Epoch 1/1000\n",
      " - 3349s - loss: 0.6695 - acc: 0.5700 - val_loss: 0.6381 - val_acc: 0.6203\n",
      "Epoch 2/1000\n",
      " - 3327s - loss: 0.6196 - acc: 0.6382 - val_loss: 0.6094 - val_acc: 0.6487\n",
      "Epoch 3/1000\n",
      " - 2733s - loss: 0.5915 - acc: 0.6662 - val_loss: 0.6038 - val_acc: 0.6523\n",
      "Epoch 4/1000\n",
      " - 2098s - loss: 0.5710 - acc: 0.6852 - val_loss: 0.5980 - val_acc: 0.6547\n",
      "Epoch 5/1000\n",
      " - 2027s - loss: 0.5518 - acc: 0.7016 - val_loss: 0.5972 - val_acc: 0.6543\n",
      "Epoch 6/1000\n",
      " - 2031s - loss: 0.5340 - acc: 0.7167 - val_loss: 0.5971 - val_acc: 0.6565\n",
      "Epoch 7/1000\n",
      " - 2035s - loss: 0.5145 - acc: 0.7304 - val_loss: 0.6017 - val_acc: 0.6557\n",
      "Epoch 8/1000\n",
      " - 2038s - loss: 0.4936 - acc: 0.7462 - val_loss: 0.6057 - val_acc: 0.6558\n",
      "Validation accuracy: 0.655798614025116, loss: 0.6057328982666599\n"
     ]
    }
   ],
   "source": [
    "reload(train_model)\n",
    "history, model, train_pred_probs, val_pred_probs = train_model.train_model(((train_vec, train_target), (val_vec, val_target)), logs_base_dir, **cnn_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score/save test and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = main_dir + 'Classification/model/party/'\n",
    "model.save(model_dir+'cnn_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101154/101154 [==============================] - 166s 2ms/sample - loss: 0.6050 - acc: 0.6550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6049941708015505, 0.6550013]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_probs = model.predict(test_vec)\n",
    "model.evaluate(test_vec, test_target, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_path = main_dir+'Classification/data/probs/party/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn', val_pred_probs, allow_pickle=True, fix_imports=True)\n",
    "np.save(probs_path+'test_pred_probs_cnn', test_pred_probs, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN - chunk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir+'Classification/data/splits/party'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'train_list'), 'rb') as fp:\n",
    "    train = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'train_ids'), 'rb') as fp:\n",
    "    train_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_list'), 'rb') as fp:\n",
    "    val = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'val_ids'), 'rb') as fp:\n",
    "    val_ids = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_list'), 'rb') as fp:\n",
    "    test = pickle.load(fp)\n",
    "with open(os.path.join(outdata_path, 'test_ids'), 'rb') as fp:\n",
    "    test_ids = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_len=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data has 303459 speeches\n",
      "It was split into 2443603 chunks\n",
      "Checks on ids and target 2443603 2443603\n",
      "Original target mean 0.5321048312951667\n",
      "New target mean 0.5447693426469029\n",
      "Original data has 101153 speeches\n",
      "It was split into 819712 chunks\n",
      "Checks on ids and target 819712 819712\n",
      "Original target mean 0.5321048312951667\n",
      "New target mean 0.5479839260618363\n",
      "Original data has 101154 speeches\n",
      "It was split into 819495 chunks\n",
      "Checks on ids and target 819495 819495\n",
      "Original target mean 0.5321094568677462\n",
      "New target mean 0.5499813909785904\n",
      "\n",
      "It took 24.5 seconds to create the dictionary\n"
     ]
    }
   ],
   "source": [
    "reload(preprocess_data)\n",
    "start_time = time.time()\n",
    "train_chunk, train_ids_chunk, train_target_chunk = preprocess_data.split_speech_to_chunks(train, train_ids, train_target, max_len=chunk_len)\n",
    "val_chunk, val_ids_chunk, val_target_chunk = preprocess_data.split_speech_to_chunks(val, val_ids, val_target, max_len=chunk_len)\n",
    "test_chunk, test_ids_chunk, test_target_chunk = preprocess_data.split_speech_to_chunks(test, test_ids, test_target, max_len=chunk_len)\n",
    "print(\"\\nIt took {:.1f} seconds to create the dictionary\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(outdata_path, 'val_ids_chunk'), 'wb') as fp:\n",
    "    pickle.dump(val_ids_chunk, fp)\n",
    "with open(os.path.join(outdata_path, 'test_ids_chunk'), 'wb') as fp:\n",
    "    pickle.dump(val_ids_chunk, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vec = np.load(os.path.join(token_path, 'train_vec_chunk.npy'))\n",
    "val_vec = np.load(os.path.join(token_path, 'val_vec_chunk.npy'))\n",
    "test_vec = np.load(os.path.join(token_path, 'test_vec_chunk.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n",
      "It took 21.7 seconds\n",
      "Preparing embedding matrix.\n",
      "Embedding matrix has been built.\n",
      "Its shape is (20000, 200).\n",
      "It took 0.2 seconds\n",
      "Train on 2443603 samples, validate on 819712 samples\n",
      "Epoch 1/1000\n",
      " - 1360s - loss: 0.6576 - acc: 0.5968 - val_loss: 0.6513 - val_acc: 0.6105\n",
      "Epoch 2/1000\n",
      " - 1417s - loss: 0.6407 - acc: 0.6207 - val_loss: 0.6468 - val_acc: 0.6101\n",
      "Epoch 3/1000\n",
      " - 1594s - loss: 0.6328 - acc: 0.6302 - val_loss: 0.6437 - val_acc: 0.6160\n",
      "Epoch 4/1000\n",
      " - 1367s - loss: 0.6257 - acc: 0.6377 - val_loss: 0.6421 - val_acc: 0.6174\n",
      "Epoch 5/1000\n",
      " - 1369s - loss: 0.6189 - acc: 0.6450 - val_loss: 0.6424 - val_acc: 0.6164\n",
      "Epoch 6/1000\n",
      " - 1362s - loss: 0.6124 - acc: 0.6514 - val_loss: 0.6422 - val_acc: 0.6180\n",
      "Validation accuracy: 0.6179901957511902, loss: 0.6422306312426115\n"
     ]
    }
   ],
   "source": [
    "history_chunk, model, train_pred_probs_chunk, val_pred_probs_chunk = train_model.train_model(((train_vec, train_target_chunk), (val_vec, val_target_chunk)), logs_base_dir, **cnn_model_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(model_dir+'cnn_chunk_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "819495/819495 [==============================] - 87s 106us/sample - loss: 0.6409 - acc: 0.6197\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6409181041485772, 0.6196792]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_probs_chunk = model.predict(test_vec)\n",
    "model.evaluate(test_vec, test_target_chunk, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn_chunk', val_pred_probs_chunk, allow_pickle=True, fix_imports=True)\n",
    "np.save(probs_path+'test_pred_probs_cnn_chunk', test_pred_probs_chunk, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate validation sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000136</td>\n",
       "      <td>0.460036</td>\n",
       "      <td>0.667681</td>\n",
       "      <td>0.559792</td>\n",
       "      <td>0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000164</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000280</td>\n",
       "      <td>0.415746</td>\n",
       "      <td>0.525855</td>\n",
       "      <td>0.470800</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000329</td>\n",
       "      <td>0.337819</td>\n",
       "      <td>0.956316</td>\n",
       "      <td>0.610796</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000342</td>\n",
       "      <td>0.414675</td>\n",
       "      <td>0.850297</td>\n",
       "      <td>0.595731</td>\n",
       "      <td>1</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids  probs_min  probs_max  probs_mean  target     preds  \\\n",
       "0  1000000136   0.460036   0.667681    0.559792       0  0.666667   \n",
       "1  1000000164   0.512244   0.512244    0.512244       1  1.000000   \n",
       "2  1000000280   0.415746   0.525855    0.470800       0  0.500000   \n",
       "3  1000000329   0.337819   0.956316    0.610796       1  0.750000   \n",
       "4  1000000342   0.414675   0.850297    0.595731       1  0.875000   \n",
       "\n",
       "   preds_probs_mean  preds_mean  \n",
       "0                 1           1  \n",
       "1                 1           1  \n",
       "2                 0           0  \n",
       "3                 1           1  \n",
       "4                 1           1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_preds_chunk = val_pred_probs_chunk > 0.5\n",
    "pred_df = pd.DataFrame({'ids': val_ids_chunk, 'target': val_target_chunk, 'probs': val_pred_probs_chunk.flatten(), 'preds': val_preds_chunk.flatten()})\n",
    "f = {'probs': [min, max, 'mean']}\n",
    "pred_aggr_df = pred_df.groupby('ids').agg(f).reset_index()\n",
    "pred_aggr_df.columns = ['ids', 'probs_min', 'probs_max', 'probs_mean']\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['target', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['preds', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df['preds_probs_mean'] = pred_aggr_df['probs_mean'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df['preds_mean'] = pred_aggr_df['preds'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_orig</th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1020203893</td>\n",
       "      <td>0.384761</td>\n",
       "      <td>0.540710</td>\n",
       "      <td>0.462735</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1030062300</td>\n",
       "      <td>0.462883</td>\n",
       "      <td>0.729484</td>\n",
       "      <td>0.608891</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1100205980</td>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.538937</td>\n",
       "      <td>0.498121</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>990019658</td>\n",
       "      <td>0.522886</td>\n",
       "      <td>0.805554</td>\n",
       "      <td>0.682641</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1130043981</td>\n",
       "      <td>0.482554</td>\n",
       "      <td>0.694468</td>\n",
       "      <td>0.558201</td>\n",
       "      <td>1</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_orig         ids  probs_min  probs_max  probs_mean  target  \\\n",
       "0            1  1020203893   0.384761   0.540710    0.462735       1   \n",
       "1            1  1030062300   0.462883   0.729484    0.608891       1   \n",
       "2            1  1100205980   0.436971   0.538937    0.498121       1   \n",
       "3            1   990019658   0.522886   0.805554    0.682641       1   \n",
       "4            1  1130043981   0.482554   0.694468    0.558201       1   \n",
       "\n",
       "      preds  preds_probs_mean  preds_mean  \n",
       "0  0.500000                 0           0  \n",
       "1  0.666667                 1           1  \n",
       "2  0.600000                 0           1  \n",
       "3  1.000000                 1           1  \n",
       "4  0.600000                 1           1  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.DataFrame({'target_orig': val_target, 'ids': val_ids})\n",
    "original_df = original_df.merge(pred_aggr_df, on=\"ids\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pred_aggr_chunk = original_df.preds_probs_mean\n",
    "val_pred_probs_aggr_chunk = original_df.probs_mean\n",
    "# val_aggr_target = pred_aggr_df.target\n",
    "# val_aggr_ids = pred_aggr_df.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'val_pred_probs_cnn_aggr_chunk', val_pred_probs_aggr_chunk, allow_pickle=True, fix_imports=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000048</td>\n",
       "      <td>0.206834</td>\n",
       "      <td>0.510755</td>\n",
       "      <td>0.395217</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000058</td>\n",
       "      <td>0.458263</td>\n",
       "      <td>0.458263</td>\n",
       "      <td>0.458263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000124</td>\n",
       "      <td>0.605943</td>\n",
       "      <td>0.814933</td>\n",
       "      <td>0.714888</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000000141</td>\n",
       "      <td>0.455183</td>\n",
       "      <td>0.753634</td>\n",
       "      <td>0.601842</td>\n",
       "      <td>1</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000000187</td>\n",
       "      <td>0.435370</td>\n",
       "      <td>0.435370</td>\n",
       "      <td>0.435370</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ids  probs_min  probs_max  probs_mean  target     preds  \\\n",
       "0  1000000048   0.206834   0.510755    0.395217       0  0.142857   \n",
       "1  1000000058   0.458263   0.458263    0.458263       0  0.000000   \n",
       "2  1000000124   0.605943   0.814933    0.714888       1  1.000000   \n",
       "3  1000000141   0.455183   0.753634    0.601842       1  0.894737   \n",
       "4  1000000187   0.435370   0.435370    0.435370       0  0.000000   \n",
       "\n",
       "   preds_probs_mean  preds_mean  \n",
       "0                 0           0  \n",
       "1                 0           0  \n",
       "2                 1           1  \n",
       "3                 1           1  \n",
       "4                 0           0  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds_chunk = test_pred_probs_chunk > 0.5\n",
    "pred_df = pd.DataFrame({'ids': test_ids_chunk, 'target': test_target_chunk, 'probs': test_pred_probs_chunk.flatten(), 'preds': test_preds_chunk.flatten()})\n",
    "f = {'probs': [min, max, 'mean']}\n",
    "pred_aggr_df = pred_df.groupby('ids').agg(f).reset_index()\n",
    "pred_aggr_df.columns = ['ids', 'probs_min', 'probs_max', 'probs_mean']\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['target', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df = pred_aggr_df.merge(pred_df[['preds', 'ids']].groupby('ids').mean().reset_index(), on='ids')\n",
    "pred_aggr_df['preds_probs_mean'] = pred_aggr_df['probs_mean'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df['preds_mean'] = pred_aggr_df['preds'].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "pred_aggr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_orig</th>\n",
       "      <th>ids</th>\n",
       "      <th>probs_min</th>\n",
       "      <th>probs_max</th>\n",
       "      <th>probs_mean</th>\n",
       "      <th>target</th>\n",
       "      <th>preds</th>\n",
       "      <th>preds_probs_mean</th>\n",
       "      <th>preds_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>970231787</td>\n",
       "      <td>0.553563</td>\n",
       "      <td>0.629133</td>\n",
       "      <td>0.581662</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>980252662</td>\n",
       "      <td>0.485569</td>\n",
       "      <td>0.683693</td>\n",
       "      <td>0.569601</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1060172004</td>\n",
       "      <td>0.535957</td>\n",
       "      <td>0.817050</td>\n",
       "      <td>0.694592</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1110115432</td>\n",
       "      <td>0.446443</td>\n",
       "      <td>0.728246</td>\n",
       "      <td>0.610706</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1030177793</td>\n",
       "      <td>0.433679</td>\n",
       "      <td>0.471363</td>\n",
       "      <td>0.452521</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target_orig         ids  probs_min  probs_max  probs_mean  target  \\\n",
       "0            1   970231787   0.553563   0.629133    0.581662       1   \n",
       "1            1   980252662   0.485569   0.683693    0.569601       1   \n",
       "2            1  1060172004   0.535957   0.817050    0.694592       1   \n",
       "3            1  1110115432   0.446443   0.728246    0.610706       1   \n",
       "4            1  1030177793   0.433679   0.471363    0.452521       1   \n",
       "\n",
       "      preds  preds_probs_mean  preds_mean  \n",
       "0  1.000000                 1           1  \n",
       "1  0.833333                 1           1  \n",
       "2  1.000000                 1           1  \n",
       "3  0.666667                 1           1  \n",
       "4  0.000000                 0           0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_df = pd.DataFrame({'target_orig': test_target, 'ids': test_ids})\n",
    "original_df = original_df.merge(pred_aggr_df, on=\"ids\")\n",
    "original_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_aggr_chunk = original_df.preds_probs_mean\n",
    "test_pred_probs_aggr_chunk = original_df.probs_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(probs_path+'test_pred_probs_cnn_aggr_chunk', test_pred_probs_aggr_chunk, allow_pickle=True, fix_imports=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
