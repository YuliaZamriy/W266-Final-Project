{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources: \n",
    "\n",
    "- Tutorial: https://www.machinelearningplus.com/nlp/topic-modeling-gensim-python/\n",
    "- Another tutorial: https://markroxor.github.io/gensim/static/notebooks/lda_training_tips.html\n",
    "    - This tutorial has a few useful links inside\n",
    "- LDA model reference: https://radimrehurek.com/gensim/models/ldamulticore.html\n",
    "- LDA coherence model reference: https://radimrehurek.com/gensim/models/coherencemodel.html\n",
    "- Coherence metrics research paper: http://svn.aksw.org/papers/2015/WSDM_Topic_Evaluation/public.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# increase cell width\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from importlib import reload\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import nltk\n",
    "# nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install gensim if necessary\n",
    "#!pip install --upgrade gensim \n",
    "#!pip install google-compute-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fbm221/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data\n",
    "from helpers import explore_data\n",
    "from helpers import preprocess_data\n",
    "from helpers import train_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fbm221/W266FinalProject/Code'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = '/home/fbm221/W266FinalProject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "indata_path = main_dir + '/Data/Gender/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdata_path = main_dir + '/saved_files/LDA/Gender/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(indata_path, 'val_list'), 'rb') as fp:\n",
    "    main_data = pickle.load(fp)\n",
    "with open(os.path.join(indata_path, 'val_ids'), 'rb') as fp:\n",
    "    main_ids = pickle.load(fp)\n",
    "with open(os.path.join(indata_path, 'val_target'), 'rb') as fp:\n",
    "    main_target = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62716"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(main_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['mr', 'senator', 'united', 'states', 'president', 'would', 'speaker', 'senate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_speech(speech):\n",
    "    processed_speech = []\n",
    "    for word in simple_preprocess(speech) :\n",
    "        if word not in stop_words:\n",
    "            processed_speech.append(WordNetLemmatizer().lemmatize(word, pos='v'))\n",
    "\n",
    "    return processed_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_speech(speeches):\n",
    "    \n",
    "    speeches_processed = [lemmatize_speech(speech) for speech in speeches]\n",
    "    \n",
    "    bigram = Phrases(sentences=speeches_processed, \n",
    "                     scoring='npmi',\n",
    "                     min_count=30, \n",
    "                     threshold=0.5)\n",
    "    \n",
    "    trigram = Phrases(sentences=bigram[speeches_processed], \n",
    "                      scoring='npmi',\n",
    "                      min_count=30, \n",
    "                      threshold=0.5)  \n",
    "    \n",
    "    bigram_mod = Phraser(bigram)\n",
    "    trigram_mod = Phraser(trigram)\n",
    "    \n",
    "    return [trigram_mod[bigram_mod[speech]] for speech in speeches_processed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "It took 429.0 seconds to process the data\n"
     ]
    }
   ],
   "source": [
    "# Only run this the first time. Otherwise import data_preprocessed below\n",
    "start_time = time.time()\n",
    "data_preprocessed = preprocess_speech(main_data)\n",
    "print(\"\\nIt took {:.1f} seconds to process the data\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_preprocessed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-176664508993>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Save data_preprocessed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_preprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data_preprocessed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'data_preprocessed' is not defined"
     ]
    }
   ],
   "source": [
    "# Only run this the first time. Otherwise import data_preprocessed below\n",
    "# Save data_preprocessed\n",
    "\n",
    "pickle.dump(data_preprocessed, open(os.path.join(indata_path, 'data_preprocessed'), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data_preprocessed\n",
    "with open(os.path.join(indata_path, 'data_preprocessed'), 'rb') as fp:\n",
    "    data_preprocessed = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens removed: 174881. 27061 tokens will be used\n"
     ]
    }
   ],
   "source": [
    "# Only run this the first time. Otherwise import word_index below\n",
    "word_index = Dictionary(data_preprocessed)\n",
    "word_index_check = Dictionary(data_preprocessed)\n",
    "word_index.filter_extremes(no_below=10, no_above=0.3)\n",
    "print(\"Number of tokens removed: {}. {} tokens will be used\".format(len(word_index_check) - len(word_index), len(word_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2cff39856a30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Only run this the first time. Otherwise import word_index below\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_as_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'word_index'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'word_index' is not defined"
     ]
    }
   ],
   "source": [
    "# Only run this the first time. Otherwise import word_index below\n",
    "word_index.save_as_text(fname=os.path.join(indata_path, 'word_index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word_index\n",
    "word_index = Dictionary.load_from_text(fname=os.path.join(indata_path, 'word_index'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most frequent words:\n",
      "know 18484\n",
      "year 17686\n",
      "want 17666\n",
      "house 17009\n",
      "rise 16885\n",
      "provide 16822\n",
      "like 16735\n",
      "come 16657\n",
      "country 16285\n",
      "congress 16188\n",
      "state 15962\n",
      "american 15662\n",
      "committee 15370\n",
      "act 15317\n",
      "think 15057\n",
      "important 15055\n",
      "get 14999\n",
      "give 14836\n",
      "first 14773\n",
      "thank 14705\n"
     ]
    }
   ],
   "source": [
    "most_frequent = sorted(word_index.dfs.items(), key=lambda x: -x[1])[:20]\n",
    "print(\"Most frequent words:\")\n",
    "for i in most_frequent:\n",
    "    print(word_index[i[0]], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [word_index.doc2bow(speech) for speech in data_preprocessed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual speech check:\n",
      "Word 3015 (\"maine\") appears 20 time(s).\n",
      "Word 2738 (\"defense\") appears 12 time(s).\n",
      "Word 501 (\"provide\") appears 7 time(s).\n",
      "Word 75 (\"continue\") appears 4 time(s).\n",
      "Word 150 (\"important\") appears 4 time(s).\n",
      "Word 175 (\"legislation\") appears 4 time(s).\n",
      "Word 208 (\"national\") appears 4 time(s).\n",
      "Word 453 (\"fund\") appears 4 time(s).\n",
      "Word 457 (\"help\") appears 4 time(s).\n",
      "Word 1043 (\"field\") appears 4 time(s).\n"
     ]
    }
   ],
   "source": [
    "print(\"Individual speech check:\")\n",
    "check = sorted(bow_corpus[100], key=lambda x: -x[1])\n",
    "for i in range(min(len(check),10)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time(s).\".format(check[i][0], \n",
    "                                                     word_index[check[i][0]], \n",
    "                                                     check[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LDA_model(dictionary, corpus, speeches, \n",
    "                            topics_range = range(1,10,1),\n",
    "                            chunksize=100,\n",
    "                            passes=10,\n",
    "                            iterations=10,\n",
    "                            eval_every=None,\n",
    "                            workers=8,\n",
    "                            random_state=100,\n",
    "                            per_word_topics=False,\n",
    "                            coherence='c_v'):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    model_list = []\n",
    "\n",
    "    for num_topics in topics_range:\n",
    "        model = LdaMulticore(corpus=corpus,\n",
    "                             id2word=dictionary,\n",
    "                             num_topics=num_topics, \n",
    "                             chunksize=chunksize,\n",
    "                             passes=passes,\n",
    "                             iterations=iterations,\n",
    "                             eval_every=eval_every,\n",
    "                             workers=workers,\n",
    "                             random_state=random_state,\n",
    "                             per_word_topics=per_word_topics)\n",
    "        \n",
    "        model_list.append(model)\n",
    "\n",
    "\n",
    "    return model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(model):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_model = CoherenceModel(model=model, \n",
    "                                     texts=data_preprocessed, \n",
    "                                     dictionary=word_index, \n",
    "                                     coherence='c_v')\n",
    "\n",
    "    cv = coherence_model.get_coherence()\n",
    "\n",
    "    return cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Params 1\n",
      "Coherence for 1 topics is 0.29\n",
      "Coherence for 6 topics is 0.42\n",
      "Coherence for 11 topics is 0.46\n",
      "Coherence for 16 topics is 0.47\n",
      "Coherence for 21 topics is 0.52\n",
      "Coherence for 26 topics is 0.52\n",
      "Coherence for 31 topics is 0.52\n",
      "Coherence for 36 topics is 0.53\n",
      "CPU times: user 52min 47s, sys: 2min 46s, total: 55min 34s\n",
      "Wall time: 42min 25s\n",
      "LDA Params 2\n",
      "Coherence for 1 topics is 0.29\n",
      "Coherence for 6 topics is 0.44\n",
      "Coherence for 11 topics is 0.50\n",
      "Coherence for 16 topics is 0.50\n",
      "Coherence for 21 topics is 0.52\n",
      "Coherence for 26 topics is 0.53\n",
      "Coherence for 31 topics is 0.54\n",
      "Coherence for 36 topics is 0.54\n",
      "CPU times: user 1h 44min 25s, sys: 5min 16s, total: 1h 49min 41s\n",
      "Wall time: 1h 7min 52s\n",
      "LDA Params 3\n",
      "Coherence for 1 topics is 0.29\n",
      "Coherence for 6 topics is 0.45\n",
      "Coherence for 11 topics is 0.51\n",
      "Coherence for 16 topics is 0.52\n",
      "Coherence for 21 topics is 0.52\n",
      "Coherence for 26 topics is 0.53\n",
      "Coherence for 31 topics is 0.54\n",
      "Coherence for 36 topics is 0.55\n",
      "CPU times: user 2h 36min 23s, sys: 7min 53s, total: 2h 44min 16s\n",
      "Wall time: 1h 36min 3s\n",
      "LDA Params 4\n",
      "Coherence for 1 topics is 0.29\n",
      "Coherence for 6 topics is 0.45\n",
      "Coherence for 11 topics is 0.50\n",
      "Coherence for 16 topics is 0.52\n",
      "Coherence for 21 topics is 0.53\n",
      "Coherence for 26 topics is 0.53\n",
      "Coherence for 31 topics is 0.55\n",
      "Coherence for 36 topics is 0.56\n",
      "CPU times: user 2h 54min 4s, sys: 9min 43s, total: 3h 3min 47s\n",
      "Wall time: 3h 37min 34s\n"
     ]
    }
   ],
   "source": [
    "# Only run this the first time:\n",
    "# # pre-process speech paramters:\n",
    "#     bigram = Phrases(sentences=speeches_processed, \n",
    "#                      scoring='npmi',\n",
    "#                      min_count=30, \n",
    "#                      threshold=0.5)\n",
    "    \n",
    "#     trigram = Phrases(sentences=bigram[speeches_processed], \n",
    "#                       scoring='npmi',\n",
    "#                       min_count=30, \n",
    "#                       threshold=0.5) \n",
    "\n",
    "### Running LDA on lda_params1 ###\n",
    "print(\"LDA Params 1\")\n",
    "lda_params1 = {\n",
    "    'topics_range': range(1,41,5),\n",
    "    'chunksize': 100,\n",
    "    'passes': 5,\n",
    "    'iterations': 5,\n",
    "    'eval_every': None,\n",
    "    'workers': 8,\n",
    "    'random_state': 100,\n",
    "    'per_word_topics': False,\n",
    "    'coherence': 'c_v'\n",
    "}\n",
    "%time model_list1, coherence_values1 = LDA_model(dictionary=word_index, corpus=bow_corpus, speeches=data_preprocessed, **lda_params1)\n",
    "\n",
    "\n",
    "### Running LDA on lda_params2 ###\n",
    "print(\"LDA Params 2\")\n",
    "lda_params2 = {\n",
    "    'topics_range': range(1,41,5),\n",
    "    'chunksize': 100,\n",
    "    'passes': 10,\n",
    "    'iterations': 10,\n",
    "    'eval_every': None,\n",
    "    'workers': 8,\n",
    "    'random_state': 100,\n",
    "    'per_word_topics': False,\n",
    "    'coherence': 'c_v'\n",
    "}\n",
    "%time model_list2, coherence_values2 = LDA_model(dictionary=word_index, corpus=bow_corpus, speeches=data_preprocessed, **lda_params2)\n",
    "\n",
    "### Running LDA on lda_params3 ###\n",
    "print(\"LDA Params 3\")\n",
    "lda_params3 = {\n",
    "    'topics_range': range(1,41,5),\n",
    "    'chunksize': 100,\n",
    "    'passes': 15,\n",
    "    'iterations': 15,\n",
    "    'eval_every': None,\n",
    "    'workers': 8,\n",
    "    'random_state': 100,\n",
    "    'per_word_topics': False,\n",
    "    'coherence': 'c_v'\n",
    "}\n",
    "%time model_list3, coherence_values3 = LDA_model(dictionary=word_index, corpus=bow_corpus, speeches=data_preprocessed, **lda_params3)\n",
    "\n",
    "### Running LDA on lda_params4 ###\n",
    "print(\"LDA Params 4\")\n",
    "lda_params4 = {\n",
    "    'topics_range': range(1,41,5),\n",
    "    'chunksize': 100,\n",
    "    'passes': 20,\n",
    "    'iterations': 20,\n",
    "    'eval_every': None,\n",
    "    'workers': 8,\n",
    "    'random_state': 100,\n",
    "    'per_word_topics': False,\n",
    "    'coherence': 'c_v'\n",
    "}\n",
    "%time model_list4, coherence_values4 = LDA_model(dictionary=word_index, corpus=bow_corpus, speeches=data_preprocessed, **lda_params4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvs = [0.53, 0.54, 0.55, 0.56]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save models\n",
    "\n",
    "topics_range = [1, 6, 11, 16, 21, 26, 31, 36]\n",
    "\n",
    "for model_list in [model_list1, model_list2, model_list3, model_list4]:\n",
    "    for model in model_list:\n",
    "        for num_topics in topics_range:\n",
    "            if model_list == model_list1:\n",
    "                model.save(outdata_path + 'lda_model_list1_' + str(num_topics))\n",
    "            if model_list == model_list2:\n",
    "                model.save(outdata_path + 'lda_model_list2_' + str(num_topics))\n",
    "            if model_list == model_list3:\n",
    "                model.save(outdata_path + 'lda_model_list3_' + str(num_topics))\n",
    "            if model_list == model_list4:\n",
    "                model.save(outdata_path + 'lda_model_list4_' + str(num_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save models in dict\n",
    "topics_range = ['1', '6', '11', '16', '21', '26', '31', '36']\n",
    "model_lists = ['model_list1_', 'model_list2_', 'model_list3_', 'model_list4_']\n",
    "lda = 'lda_'\n",
    "models_dict = {}\n",
    "\n",
    "for model_list in model_lists:\n",
    "    for num_topics in topics_range:\n",
    "        filename = model_list + num_topics\n",
    "        model = LdaMulticore.load(os.path.join(outdata_path,lda+filename))\n",
    "        models_dict[filename] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_list1_1': <gensim.models.ldamulticore.LdaMulticore at 0x7f047ab055c0>,\n",
       " 'model_list1_6': <gensim.models.ldamulticore.LdaMulticore at 0x7f047a548fd0>,\n",
       " 'model_list1_11': <gensim.models.ldamulticore.LdaMulticore at 0x7f047a1049e8>,\n",
       " 'model_list1_16': <gensim.models.ldamulticore.LdaMulticore at 0x7f0479cc13c8>,\n",
       " 'model_list1_21': <gensim.models.ldamulticore.LdaMulticore at 0x7f0479879d68>,\n",
       " 'model_list1_26': <gensim.models.ldamulticore.LdaMulticore at 0x7f0479436748>,\n",
       " 'model_list1_31': <gensim.models.ldamulticore.LdaMulticore at 0x7f0478ff0128>,\n",
       " 'model_list1_36': <gensim.models.ldamulticore.LdaMulticore at 0x7f0478baaac8>,\n",
       " 'model_list2_1': <gensim.models.ldamulticore.LdaMulticore at 0x7f04787654a8>,\n",
       " 'model_list2_6': <gensim.models.ldamulticore.LdaMulticore at 0x7f047831de48>,\n",
       " 'model_list2_11': <gensim.models.ldamulticore.LdaMulticore at 0x7f0477ed8828>,\n",
       " 'model_list2_16': <gensim.models.ldamulticore.LdaMulticore at 0x7f0477a95208>,\n",
       " 'model_list2_21': <gensim.models.ldamulticore.LdaMulticore at 0x7f047764eba8>,\n",
       " 'model_list2_26': <gensim.models.ldamulticore.LdaMulticore at 0x7f047728a588>,\n",
       " 'model_list2_31': <gensim.models.ldamulticore.LdaMulticore at 0x7f0476e42f28>,\n",
       " 'model_list2_36': <gensim.models.ldamulticore.LdaMulticore at 0x7f04769fe908>,\n",
       " 'model_list3_1': <gensim.models.ldamulticore.LdaMulticore at 0x7f04765ba2e8>,\n",
       " 'model_list3_6': <gensim.models.ldamulticore.LdaMulticore at 0x7f0476175c88>,\n",
       " 'model_list3_11': <gensim.models.ldamulticore.LdaMulticore at 0x7f0475d2f668>,\n",
       " 'model_list3_16': <gensim.models.ldamulticore.LdaMulticore at 0x7f04758e7fd0>,\n",
       " 'model_list3_21': <gensim.models.ldamulticore.LdaMulticore at 0x7f04754a39e8>,\n",
       " 'model_list3_26': <gensim.models.ldamulticore.LdaMulticore at 0x7f047505f3c8>,\n",
       " 'model_list3_31': <gensim.models.ldamulticore.LdaMulticore at 0x7f0474c18d30>,\n",
       " 'model_list3_36': <gensim.models.ldamulticore.LdaMulticore at 0x7f04747d56d8>,\n",
       " 'model_list4_1': <gensim.models.ldamulticore.LdaMulticore at 0x7f047438efd0>,\n",
       " 'model_list4_6': <gensim.models.ldamulticore.LdaMulticore at 0x7f0473fc99e8>,\n",
       " 'model_list4_11': <gensim.models.ldamulticore.LdaMulticore at 0x7f0473b84390>,\n",
       " 'model_list4_16': <gensim.models.ldamulticore.LdaMulticore at 0x7f047373dcf8>,\n",
       " 'model_list4_21': <gensim.models.ldamulticore.LdaMulticore at 0x7f04732fa6a0>,\n",
       " 'model_list4_26': <gensim.models.ldamulticore.LdaMulticore at 0x7f0472eb3fd0>,\n",
       " 'model_list4_31': <gensim.models.ldamulticore.LdaMulticore at 0x7f0472a6f9b0>,\n",
       " 'model_list4_36': <gensim.models.ldamulticore.LdaMulticore at 0x7f047262a358>}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the model based on the highest coherence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10\n",
    "num_topics = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Only run this the first time ##\n",
    "# number of words per topic to display (can be any number within vocabulary size)\n",
    "num_words = 10\n",
    "num_topics = 36\n",
    "\n",
    "# Model 1\n",
    "top_topics1 = models_dict['model_list1_36'].top_topics(corpus=bow_corpus, \n",
    "                                      texts=data_preprocessed,\n",
    "                                      coherence='c_v', \n",
    "                                      topn=num_words)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence1 = sum([t[1] for t in top_topics1]) / num_topics\n",
    "\n",
    "# Model 2\n",
    "top_topics2 = models_dict['model_list2_36'].top_topics(corpus=bow_corpus, \n",
    "                                      texts=data_preprocessed,\n",
    "                                      coherence='c_v', \n",
    "                                      topn=num_words)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence2 = sum([t[1] for t in top_topics2]) / num_topics\n",
    "\n",
    "# Model 3\n",
    "top_topics3 = models_dict['model_list3_36'].top_topics(corpus=bow_corpus, \n",
    "                                      texts=data_preprocessed,\n",
    "                                      coherence='c_v', \n",
    "                                      topn=num_words)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence3 = sum([t[1] for t in top_topics3]) / num_topics\n",
    "\n",
    "# Model 4\n",
    "top_topics4 = models_dict['model_list4_36'].top_topics(corpus=bow_corpus, \n",
    "                                      texts=data_preprocessed,\n",
    "                                      coherence='c_v', \n",
    "                                      topn=num_words)\n",
    "\n",
    "# Average topic coherence is the sum of topic coherences of all topics, divided by the number of topics.\n",
    "avg_topic_coherence4 = sum([t[1] for t in top_topics4]) / num_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save top_topics and avg_topic_coherence ##\n",
    "\n",
    "with open(os.path.join(outdata_path, \"top_topics.txt\"), \"w\") as output:\n",
    "    output.write(str(top_topics))\n",
    "\n",
    "with open(os.path.join(outdata_path, \"avg_topic_coherence.txt\"), \"w\") as output:\n",
    "    output.write(str(avg_topic_coherence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load top_topics and avg_topic coherence ##\n",
    "\n",
    "with open(os.path.join(outdata_path, \"top_topics.txt\"), \"r\") as output:\n",
    "    top_topics = output.read()\n",
    "\n",
    "with open(os.path.join(outdata_path, \"avg_topic_coherence.txt\"), \"r\") as output:\n",
    "    avg_topic_coherence = output.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0.5817462661651895, 0.5942108548352567, 0.6013899442646253, 0.6058619752990757]'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_topic_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists of data\n",
    "models = ['Model 1', 'Model 2', 'Model 3', 'Model 4']\n",
    "#top_topics = [top_topics1, top_topics2, top_topics3, top_topics4]\n",
    "avg_topic_coherence = [0.582, 0.594, 0.601, 0.606]\n",
    "passes = [5, 10, 15, 20]\n",
    "iterations = [5, 10, 15, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_comparisons = pd.DataFrame(\n",
    "    {'Model Number': models,\n",
    "     'Coherence Values': cvs,\n",
    "     'Average Topic Coherence': avg_topic_coherence,\n",
    "     'Number of Topics': num_topics,\n",
    "     'Passes': passes,\n",
    "     'Iterations': iterations\n",
    "     #'Top Topics': top_topics top 10 words/score\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Number</th>\n",
       "      <th>Coherence Values</th>\n",
       "      <th>Average Topic Coherence</th>\n",
       "      <th>Number of Topics</th>\n",
       "      <th>Passes</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.582</td>\n",
       "      <td>36</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.594</td>\n",
       "      <td>36</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.601</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.606</td>\n",
       "      <td>36</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Number  Coherence Values  Average Topic Coherence  Number of Topics  \\\n",
       "0      Model 1              0.53                    0.582                36   \n",
       "1      Model 2              0.54                    0.594                36   \n",
       "2      Model 3              0.55                    0.601                36   \n",
       "3      Model 4              0.56                    0.606                36   \n",
       "\n",
       "   Passes  Iterations  \n",
       "0       5           5  \n",
       "1      10          10  \n",
       "2      15          15  \n",
       "3      20          20  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We see that Model 4 is performing the best in terms of coherence, with 20 passes and 20 iterations. We find that some topics seem to be related and may be repetitive, but in order to keep all salient topics in the dataset, we need to keep the 36 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_model = models_dict['model_list4_36']\n",
    "num_topics = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_keywords_dict(ldamodel, num_topics):\n",
    "    topic_dict = {}\n",
    "    for i in range(num_topics):\n",
    "        topic_dict[i] = [word[0] for word in ldamodel.show_topic(i)]\n",
    "    return topic_dict\n",
    "keywords_dict = get_topics_keywords_dict(optimal_model, num_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict_names = keywords_dict.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_dict_names[\"Crime and Immigration\"] = keywords_dict_names.pop(0)\n",
    "keywords_dict_names[\"Military\"] = keywords_dict_names.pop(1)\n",
    "keywords_dict_names[\"Environment\"] = keywords_dict_names.pop(2)\n",
    "keywords_dict_names[\"Elections and Parties\"] = keywords_dict_names.pop(3)\n",
    "keywords_dict_names[\"Random Verbs\"] = keywords_dict_names.pop(4)\n",
    "keywords_dict_names[\"Judicial System\"] = keywords_dict_names.pop(5)\n",
    "keywords_dict_names[\"The Navy\"] = keywords_dict_names.pop(6)\n",
    "keywords_dict_names[\"War and Defense\"] = keywords_dict_names.pop(7)\n",
    "keywords_dict_names[\"Judicial Nominations\"] = keywords_dict_names.pop(8)\n",
    "keywords_dict_names[\"Common Phrases\"] = keywords_dict_names.pop(9)\n",
    "keywords_dict_names[\"Foreign Policy\"] = keywords_dict_names.pop(10)\n",
    "keywords_dict_names[\"Healthcare and Women's Health\"] = keywords_dict_names.pop(11)\n",
    "keywords_dict_names[\"National Security\"] = keywords_dict_names.pop(12)\n",
    "keywords_dict_names[\"Positive Words\"] = keywords_dict_names.pop(13)\n",
    "keywords_dict_names[\"Agriculture\"] = keywords_dict_names.pop(14)\n",
    "keywords_dict_names[\"Economy\"] = keywords_dict_names.pop(15)\n",
    "keywords_dict_names[\"Legislation\"] = keywords_dict_names.pop(16)\n",
    "keywords_dict_names[\"Poverty and Welfare\"] = keywords_dict_names.pop(17)\n",
    "keywords_dict_names[\"Common Congressional Phrases\"] = keywords_dict_names.pop(18)\n",
    "keywords_dict_names[\"Natural Disasters\"] = keywords_dict_names.pop(19)\n",
    "keywords_dict_names[\"Federal Assistance Programs\"] = keywords_dict_names.pop(20)\n",
    "keywords_dict_names[\"Education\"] = keywords_dict_names.pop(21)\n",
    "keywords_dict_names[\"Foreign Trade\"] = keywords_dict_names.pop(22)\n",
    "keywords_dict_names[\"Children's Diseases\"] = keywords_dict_names.pop(23)\n",
    "keywords_dict_names[\"Positive Words 2\"] = keywords_dict_names.pop(24)\n",
    "keywords_dict_names[\"Infrastructure\"] = keywords_dict_names.pop(25)\n",
    "keywords_dict_names[\"Random Verbs 2\"] = keywords_dict_names.pop(26)\n",
    "keywords_dict_names[\"Diplomacy and Security\"] = keywords_dict_names.pop(27)\n",
    "keywords_dict_names[\"Finance and Business\"] = keywords_dict_names.pop(28)\n",
    "keywords_dict_names[\"Energy\"] = keywords_dict_names.pop(29)\n",
    "keywords_dict_names[\"Scientific Research\"] = keywords_dict_names.pop(30)\n",
    "keywords_dict_names[\"States\"] = keywords_dict_names.pop(31)\n",
    "keywords_dict_names[\"Budgets and Spending\"] = keywords_dict_names.pop(32)\n",
    "keywords_dict_names[\"Costs\"] = keywords_dict_names.pop(33)\n",
    "keywords_dict_names[\"Taxes and Welfare\"] = keywords_dict_names.pop(34)\n",
    "keywords_dict_names[\"Great Nation\"] = keywords_dict_names.pop(35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping from keywords_dict to keywords_dict_names:\n",
    "\n",
    "mapping = {0: \"Crime and Immigration\", 1: \"Military\", 2: \"Environment\", 3: \"Elections and Parties\",\n",
    "          4: \"Random Verbs\", 5: \"Judicial System\", 6: \"The Navy\", 7: \"War and Defense\",\n",
    "          8: \"Judicial Nominations\", 9: \"Common Phrases\", 10: \"Foreign Policy\", 11: \"Healthcare and Women's Health\",\n",
    "          12: \"National Security\", 13: \"Positive Words\", 14: \"Agriculture\", 15: \"Economy\", 16: \"Legislation\",\n",
    "          17: \"Poverty and Welfare\", 18: \"Common Congressional Phrases\", 19: \"Natural Disasters\", \n",
    "          20: \"Federal Assistance Programs\", 21: \"Education\", 22: \"Foreign Trade\", 23: \"Children's Diseases\",\n",
    "          24: \"Positive Words 2\", 25: \"Infrastructure\", 26: \"Random Verbs 2\", 27: \"Diplomacy and Security\",\n",
    "          28: \"Finance and Business\", 29: \"Energy\", 30: \"Scientific Research\", 31: \"States\", 32: \"Budgets and Spending\",\n",
    "          33: \"Costs\", 34: \"Taxes and Welfare\", 35: \"Great Nation\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['drug',\n",
       "  'crime',\n",
       "  'border',\n",
       "  'immigration',\n",
       "  'gun',\n",
       "  'violence',\n",
       "  'act',\n",
       "  'mexico',\n",
       "  'law_enforcement',\n",
       "  'victims'],\n",
       " 1: ['veterans',\n",
       "  'service',\n",
       "  'serve',\n",
       "  'va',\n",
       "  'military',\n",
       "  'honor',\n",
       "  'men_women',\n",
       "  'country',\n",
       "  'families',\n",
       "  'sacrifice'],\n",
       " 2: ['water',\n",
       "  'land',\n",
       "  'environmental',\n",
       "  'forest',\n",
       "  'project',\n",
       "  'national',\n",
       "  'public',\n",
       "  'area',\n",
       "  'environment',\n",
       "  'park'],\n",
       " 3: ['vote',\n",
       "  'congress',\n",
       "  'political',\n",
       "  'republican',\n",
       "  'public',\n",
       "  'party',\n",
       "  'democratic',\n",
       "  'house',\n",
       "  'campaign',\n",
       "  'election'],\n",
       " 4: ['get',\n",
       "  'money',\n",
       "  'want',\n",
       "  'know',\n",
       "  'dont',\n",
       "  'tell',\n",
       "  'back',\n",
       "  'come',\n",
       "  'let',\n",
       "  'pay'],\n",
       " 5: ['law',\n",
       "  'right',\n",
       "  'court',\n",
       "  'case',\n",
       "  'constitution',\n",
       "  'constitutional',\n",
       "  'judge',\n",
       "  'legal',\n",
       "  'federal',\n",
       "  'supreme_court'],\n",
       " 6: ['fire',\n",
       "  'ship',\n",
       "  'port',\n",
       "  'navy',\n",
       "  'haiti',\n",
       "  'flag',\n",
       "  'coast_guard',\n",
       "  'officer',\n",
       "  'guam',\n",
       "  'beach'],\n",
       " 7: ['military',\n",
       "  'war',\n",
       "  'iraq',\n",
       "  'troop',\n",
       "  'defense',\n",
       "  'force',\n",
       "  'army',\n",
       "  'soldier',\n",
       "  'afghanistan',\n",
       "  'general'],\n",
       " 8: ['vote',\n",
       "  'judge',\n",
       "  'nomination',\n",
       "  'senators',\n",
       "  'district',\n",
       "  'record',\n",
       "  'present',\n",
       "  'ms',\n",
       "  'confirm',\n",
       "  'district_columbia'],\n",
       " 9: ['house',\n",
       "  'committee',\n",
       "  'resolution',\n",
       "  'rule',\n",
       "  'ask_unanimous_consent',\n",
       "  'follow',\n",
       "  'order',\n",
       "  'may',\n",
       "  'hear',\n",
       "  'members'],\n",
       " 10: ['government',\n",
       "  'peace',\n",
       "  'freedom',\n",
       "  'israel',\n",
       "  'must',\n",
       "  'soviet',\n",
       "  'democracy',\n",
       "  'jewish',\n",
       "  'continue',\n",
       "  'world'],\n",
       " 11: ['women',\n",
       "  'medical',\n",
       "  'care',\n",
       "  'health',\n",
       "  'doctor',\n",
       "  'patients',\n",
       "  'hospital',\n",
       "  'abortion',\n",
       "  'service',\n",
       "  'access'],\n",
       " 12: ['report',\n",
       "  'information',\n",
       "  'department',\n",
       "  'intelligence',\n",
       "  'government',\n",
       "  'commission',\n",
       "  'office',\n",
       "  'committee',\n",
       "  'administration',\n",
       "  'security'],\n",
       " 13: ['community',\n",
       "  'service',\n",
       "  'national',\n",
       "  'recognize',\n",
       "  'award',\n",
       "  'association',\n",
       "  'center',\n",
       "  'city',\n",
       "  'honor',\n",
       "  'year'],\n",
       " 14: ['farm',\n",
       "  'farmers',\n",
       "  'agriculture',\n",
       "  'food',\n",
       "  'agricultural',\n",
       "  'program',\n",
       "  'price',\n",
       "  'rural',\n",
       "  'arkansas',\n",
       "  'market'],\n",
       " 15: ['job',\n",
       "  'workers',\n",
       "  'economy',\n",
       "  'labor',\n",
       "  'create',\n",
       "  'economic',\n",
       "  'american',\n",
       "  'employees',\n",
       "  'americans',\n",
       "  'help'],\n",
       " 16: ['legislation',\n",
       "  'act',\n",
       "  'provision',\n",
       "  'require',\n",
       "  'congress',\n",
       "  'federal',\n",
       "  'provide',\n",
       "  'process',\n",
       "  'section',\n",
       "  'change'],\n",
       " 17: ['children',\n",
       "  'program',\n",
       "  'families',\n",
       "  'welfare',\n",
       "  'child',\n",
       "  'poor',\n",
       "  'family',\n",
       "  'poverty',\n",
       "  'live',\n",
       "  'care'],\n",
       " 18: ['amendment',\n",
       "  'chairman',\n",
       "  'gentleman',\n",
       "  'committee',\n",
       "  'offer',\n",
       "  'vote',\n",
       "  'want',\n",
       "  'amendments',\n",
       "  'thank',\n",
       "  'distinguish'],\n",
       " 19: ['emergency',\n",
       "  'home',\n",
       "  'help',\n",
       "  'texas',\n",
       "  'state',\n",
       "  'florida',\n",
       "  'flood',\n",
       "  'disaster',\n",
       "  'damage',\n",
       "  'communities'],\n",
       " 20: ['program',\n",
       "  'fund',\n",
       "  'provide',\n",
       "  'million',\n",
       "  'house',\n",
       "  'service',\n",
       "  'include',\n",
       "  'assistance',\n",
       "  'federal',\n",
       "  'grant'],\n",
       " 21: ['school',\n",
       "  'education',\n",
       "  'students',\n",
       "  'college',\n",
       "  'children',\n",
       "  'program',\n",
       "  'educational',\n",
       "  'teachers',\n",
       "  'young',\n",
       "  'learn'],\n",
       " 22: ['trade',\n",
       "  'company',\n",
       "  'industry',\n",
       "  'market',\n",
       "  'american',\n",
       "  'export',\n",
       "  'foreign',\n",
       "  'products',\n",
       "  'countries',\n",
       "  'import'],\n",
       " 23: ['children',\n",
       "  'health',\n",
       "  'child',\n",
       "  'disease',\n",
       "  'treatment',\n",
       "  'live',\n",
       "  'parent',\n",
       "  'national',\n",
       "  'research',\n",
       "  'help'],\n",
       " 24: ['serve',\n",
       "  'service',\n",
       "  'family',\n",
       "  'honor',\n",
       "  'dr',\n",
       "  'member',\n",
       "  'life',\n",
       "  'career',\n",
       "  'university',\n",
       "  'john'],\n",
       " 25: ['transportation',\n",
       "  'safety',\n",
       "  'project',\n",
       "  'system',\n",
       "  'highway',\n",
       "  'construction',\n",
       "  'air',\n",
       "  'build',\n",
       "  'airport',\n",
       "  'truck'],\n",
       " 26: ['think',\n",
       "  'want',\n",
       "  'come',\n",
       "  'know',\n",
       "  'get',\n",
       "  'issue',\n",
       "  'talk',\n",
       "  'way',\n",
       "  'see',\n",
       "  'country'],\n",
       " 27: ['world',\n",
       "  'nations',\n",
       "  'international',\n",
       "  'policy',\n",
       "  'countries',\n",
       "  'nuclear',\n",
       "  'must',\n",
       "  'administration',\n",
       "  'agreement',\n",
       "  'security'],\n",
       " 28: ['bank',\n",
       "  'loan',\n",
       "  'financial',\n",
       "  'credit',\n",
       "  'small_business',\n",
       "  'market',\n",
       "  'business',\n",
       "  'company',\n",
       "  'small_businesses',\n",
       "  'capital'],\n",
       " 29: ['energy',\n",
       "  'oil',\n",
       "  'price',\n",
       "  'fuel',\n",
       "  'production',\n",
       "  'power',\n",
       "  'natural_gas',\n",
       "  'use',\n",
       "  'supply',\n",
       "  'gas'],\n",
       " 30: ['research',\n",
       "  'technology',\n",
       "  'new',\n",
       "  'science',\n",
       "  'space',\n",
       "  'program',\n",
       "  'test',\n",
       "  'system',\n",
       "  'national',\n",
       "  'use'],\n",
       " 31: ['state',\n",
       "  'washington',\n",
       "  'colorado',\n",
       "  'california',\n",
       "  'alaska',\n",
       "  'indian',\n",
       "  'minnesota',\n",
       "  'nevada',\n",
       "  'governor',\n",
       "  'native'],\n",
       " 32: ['budget',\n",
       "  'spend',\n",
       "  'billion',\n",
       "  'cut',\n",
       "  'deficit',\n",
       "  'congress',\n",
       "  'debt',\n",
       "  'year',\n",
       "  'tax',\n",
       "  'vote'],\n",
       " 33: ['percent',\n",
       "  'cost',\n",
       "  'increase',\n",
       "  'million',\n",
       "  'year',\n",
       "  'number',\n",
       "  'billion',\n",
       "  'rate',\n",
       "  'less',\n",
       "  'level'],\n",
       " 34: ['tax',\n",
       "  'pay',\n",
       "  'medicare',\n",
       "  'benefit',\n",
       "  'plan',\n",
       "  'social_security',\n",
       "  'income',\n",
       "  'cost',\n",
       "  'insurance',\n",
       "  'seniors'],\n",
       " 35: ['history',\n",
       "  'great',\n",
       "  'nation',\n",
       "  'day',\n",
       "  'american',\n",
       "  'live',\n",
       "  'first',\n",
       "  'world',\n",
       "  'americans',\n",
       "  'life']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Crime and Immigration': ['drug',\n",
       "  'crime',\n",
       "  'border',\n",
       "  'immigration',\n",
       "  'gun',\n",
       "  'violence',\n",
       "  'act',\n",
       "  'mexico',\n",
       "  'law_enforcement',\n",
       "  'victims'],\n",
       " 'Military': ['veterans',\n",
       "  'service',\n",
       "  'serve',\n",
       "  'va',\n",
       "  'military',\n",
       "  'honor',\n",
       "  'men_women',\n",
       "  'country',\n",
       "  'families',\n",
       "  'sacrifice'],\n",
       " 'Environment': ['water',\n",
       "  'land',\n",
       "  'environmental',\n",
       "  'forest',\n",
       "  'project',\n",
       "  'national',\n",
       "  'public',\n",
       "  'area',\n",
       "  'environment',\n",
       "  'park'],\n",
       " 'Elections and Parties': ['vote',\n",
       "  'congress',\n",
       "  'political',\n",
       "  'republican',\n",
       "  'public',\n",
       "  'party',\n",
       "  'democratic',\n",
       "  'house',\n",
       "  'campaign',\n",
       "  'election'],\n",
       " 'Random Verbs': ['get',\n",
       "  'money',\n",
       "  'want',\n",
       "  'know',\n",
       "  'dont',\n",
       "  'tell',\n",
       "  'back',\n",
       "  'come',\n",
       "  'let',\n",
       "  'pay'],\n",
       " 'Judicial System': ['law',\n",
       "  'right',\n",
       "  'court',\n",
       "  'case',\n",
       "  'constitution',\n",
       "  'constitutional',\n",
       "  'judge',\n",
       "  'legal',\n",
       "  'federal',\n",
       "  'supreme_court'],\n",
       " 'The Navy': ['fire',\n",
       "  'ship',\n",
       "  'port',\n",
       "  'navy',\n",
       "  'haiti',\n",
       "  'flag',\n",
       "  'coast_guard',\n",
       "  'officer',\n",
       "  'guam',\n",
       "  'beach'],\n",
       " 'War and Defense': ['military',\n",
       "  'war',\n",
       "  'iraq',\n",
       "  'troop',\n",
       "  'defense',\n",
       "  'force',\n",
       "  'army',\n",
       "  'soldier',\n",
       "  'afghanistan',\n",
       "  'general'],\n",
       " 'Judicial Nominations': ['vote',\n",
       "  'judge',\n",
       "  'nomination',\n",
       "  'senators',\n",
       "  'district',\n",
       "  'record',\n",
       "  'present',\n",
       "  'ms',\n",
       "  'confirm',\n",
       "  'district_columbia'],\n",
       " 'Common Phrases': ['house',\n",
       "  'committee',\n",
       "  'resolution',\n",
       "  'rule',\n",
       "  'ask_unanimous_consent',\n",
       "  'follow',\n",
       "  'order',\n",
       "  'may',\n",
       "  'hear',\n",
       "  'members'],\n",
       " 'Foreign Policy': ['government',\n",
       "  'peace',\n",
       "  'freedom',\n",
       "  'israel',\n",
       "  'must',\n",
       "  'soviet',\n",
       "  'democracy',\n",
       "  'jewish',\n",
       "  'continue',\n",
       "  'world'],\n",
       " \"Healthcare and Women's Health\": ['women',\n",
       "  'medical',\n",
       "  'care',\n",
       "  'health',\n",
       "  'doctor',\n",
       "  'patients',\n",
       "  'hospital',\n",
       "  'abortion',\n",
       "  'service',\n",
       "  'access'],\n",
       " 'National Security': ['report',\n",
       "  'information',\n",
       "  'department',\n",
       "  'intelligence',\n",
       "  'government',\n",
       "  'commission',\n",
       "  'office',\n",
       "  'committee',\n",
       "  'administration',\n",
       "  'security'],\n",
       " 'Positive Words': ['community',\n",
       "  'service',\n",
       "  'national',\n",
       "  'recognize',\n",
       "  'award',\n",
       "  'association',\n",
       "  'center',\n",
       "  'city',\n",
       "  'honor',\n",
       "  'year'],\n",
       " 'Agriculture': ['farm',\n",
       "  'farmers',\n",
       "  'agriculture',\n",
       "  'food',\n",
       "  'agricultural',\n",
       "  'program',\n",
       "  'price',\n",
       "  'rural',\n",
       "  'arkansas',\n",
       "  'market'],\n",
       " 'Economy': ['job',\n",
       "  'workers',\n",
       "  'economy',\n",
       "  'labor',\n",
       "  'create',\n",
       "  'economic',\n",
       "  'american',\n",
       "  'employees',\n",
       "  'americans',\n",
       "  'help'],\n",
       " 'Legislation': ['legislation',\n",
       "  'act',\n",
       "  'provision',\n",
       "  'require',\n",
       "  'congress',\n",
       "  'federal',\n",
       "  'provide',\n",
       "  'process',\n",
       "  'section',\n",
       "  'change'],\n",
       " 'Poverty and Welfare': ['children',\n",
       "  'program',\n",
       "  'families',\n",
       "  'welfare',\n",
       "  'child',\n",
       "  'poor',\n",
       "  'family',\n",
       "  'poverty',\n",
       "  'live',\n",
       "  'care'],\n",
       " 'Common Congressional Phrases': ['amendment',\n",
       "  'chairman',\n",
       "  'gentleman',\n",
       "  'committee',\n",
       "  'offer',\n",
       "  'vote',\n",
       "  'want',\n",
       "  'amendments',\n",
       "  'thank',\n",
       "  'distinguish'],\n",
       " 'Natural Disasters': ['emergency',\n",
       "  'home',\n",
       "  'help',\n",
       "  'texas',\n",
       "  'state',\n",
       "  'florida',\n",
       "  'flood',\n",
       "  'disaster',\n",
       "  'damage',\n",
       "  'communities'],\n",
       " 'Federal Assistance Programs': ['program',\n",
       "  'fund',\n",
       "  'provide',\n",
       "  'million',\n",
       "  'house',\n",
       "  'service',\n",
       "  'include',\n",
       "  'assistance',\n",
       "  'federal',\n",
       "  'grant'],\n",
       " 'Education': ['school',\n",
       "  'education',\n",
       "  'students',\n",
       "  'college',\n",
       "  'children',\n",
       "  'program',\n",
       "  'educational',\n",
       "  'teachers',\n",
       "  'young',\n",
       "  'learn'],\n",
       " 'Foreign Trade': ['trade',\n",
       "  'company',\n",
       "  'industry',\n",
       "  'market',\n",
       "  'american',\n",
       "  'export',\n",
       "  'foreign',\n",
       "  'products',\n",
       "  'countries',\n",
       "  'import'],\n",
       " \"Children's Diseases\": ['children',\n",
       "  'health',\n",
       "  'child',\n",
       "  'disease',\n",
       "  'treatment',\n",
       "  'live',\n",
       "  'parent',\n",
       "  'national',\n",
       "  'research',\n",
       "  'help'],\n",
       " 'Positive Words 2': ['serve',\n",
       "  'service',\n",
       "  'family',\n",
       "  'honor',\n",
       "  'dr',\n",
       "  'member',\n",
       "  'life',\n",
       "  'career',\n",
       "  'university',\n",
       "  'john'],\n",
       " 'Infrastructure': ['transportation',\n",
       "  'safety',\n",
       "  'project',\n",
       "  'system',\n",
       "  'highway',\n",
       "  'construction',\n",
       "  'air',\n",
       "  'build',\n",
       "  'airport',\n",
       "  'truck'],\n",
       " 'Random Verbs 2': ['think',\n",
       "  'want',\n",
       "  'come',\n",
       "  'know',\n",
       "  'get',\n",
       "  'issue',\n",
       "  'talk',\n",
       "  'way',\n",
       "  'see',\n",
       "  'country'],\n",
       " 'Diplomacy and Security': ['world',\n",
       "  'nations',\n",
       "  'international',\n",
       "  'policy',\n",
       "  'countries',\n",
       "  'nuclear',\n",
       "  'must',\n",
       "  'administration',\n",
       "  'agreement',\n",
       "  'security'],\n",
       " 'Finance and Business': ['bank',\n",
       "  'loan',\n",
       "  'financial',\n",
       "  'credit',\n",
       "  'small_business',\n",
       "  'market',\n",
       "  'business',\n",
       "  'company',\n",
       "  'small_businesses',\n",
       "  'capital'],\n",
       " 'Energy': ['energy',\n",
       "  'oil',\n",
       "  'price',\n",
       "  'fuel',\n",
       "  'production',\n",
       "  'power',\n",
       "  'natural_gas',\n",
       "  'use',\n",
       "  'supply',\n",
       "  'gas'],\n",
       " 'Scientific Research': ['research',\n",
       "  'technology',\n",
       "  'new',\n",
       "  'science',\n",
       "  'space',\n",
       "  'program',\n",
       "  'test',\n",
       "  'system',\n",
       "  'national',\n",
       "  'use'],\n",
       " 'States': ['state',\n",
       "  'washington',\n",
       "  'colorado',\n",
       "  'california',\n",
       "  'alaska',\n",
       "  'indian',\n",
       "  'minnesota',\n",
       "  'nevada',\n",
       "  'governor',\n",
       "  'native'],\n",
       " 'Budgets and Spending': ['budget',\n",
       "  'spend',\n",
       "  'billion',\n",
       "  'cut',\n",
       "  'deficit',\n",
       "  'congress',\n",
       "  'debt',\n",
       "  'year',\n",
       "  'tax',\n",
       "  'vote'],\n",
       " 'Costs': ['percent',\n",
       "  'cost',\n",
       "  'increase',\n",
       "  'million',\n",
       "  'year',\n",
       "  'number',\n",
       "  'billion',\n",
       "  'rate',\n",
       "  'less',\n",
       "  'level'],\n",
       " 'Taxes and Welfare': ['tax',\n",
       "  'pay',\n",
       "  'medicare',\n",
       "  'benefit',\n",
       "  'plan',\n",
       "  'social_security',\n",
       "  'income',\n",
       "  'cost',\n",
       "  'insurance',\n",
       "  'seniors'],\n",
       " 'Great Nation': ['history',\n",
       "  'great',\n",
       "  'nation',\n",
       "  'day',\n",
       "  'american',\n",
       "  'live',\n",
       "  'first',\n",
       "  'world',\n",
       "  'americans',\n",
       "  'life']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords_dict_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas.plotting import table\n",
    "import subprocess\n",
    "\n",
    "df=pd.DataFrame.from_dict(keywords_dict_names ,orient='index')\n",
    "\n",
    "\n",
    "df.to_html('table.html')\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(outdata_path, \"keywords_dict_gender.txt\"),\"w\")\n",
    "f.write( str(keywords_dict) )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(os.path.join(outdata_path, \"keywords_dict_gender_names.txt\"),\"w\")\n",
    "f.write( str(keywords_dict_names) )\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(8, 0.75803095), (9, 0.20417425)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_model[bow_corpus][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Append primary and secondary topics to the speech file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62716, 9)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def append_topic(ldamodel, corpus, speeches, ids, kw_dict, mapping):\n",
    "    # Init output\n",
    "    speech_topics_df = pd.DataFrame()\n",
    "    \n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        sorted_topics = sorted(row, key=lambda x: -x[1])\n",
    "        topic_count = len(sorted_topics)\n",
    "        \n",
    "        topic1_num, topic1_contrib = sorted_topics[0]\n",
    "        topic1_name = mapping[topic1_num]\n",
    "        topic1_keywords = ','.join(kw_dict[topic1_num])\n",
    "        \n",
    "        if topic_count > 1:\n",
    "            topic2_num, topic2_contrib = sorted_topics[1]\n",
    "            topic2_name = mapping[topic2_num]\n",
    "        else:\n",
    "            topic2_num, topic2_contrib = -1, 0\n",
    "            topic2_name = \"None\"\n",
    "            \n",
    "        \n",
    "        new_row = [topic_count, int(topic1_num), topic1_name, round(topic1_contrib,2), topic1_keywords, int(topic2_num), topic2_name, round(topic2_contrib,2)]\n",
    "        speech_topics_df = speech_topics_df.append(pd.Series(new_row), ignore_index=True)\n",
    "\n",
    "    speech_topics_df = pd.concat([speech_topics_df, pd.Series(ids)], axis=1)\n",
    "    speech_topics_df.columns = ['Topic_Count', 'Prim_Topic', 'Prim_Topic_Name', 'Prim_Topic_Contrib', 'Prim_Topic_Keywords', \n",
    "                                'Sec_Topic', 'Sec_Topic_Name', 'Sec_Topic_Contrib', 'Speech_id']\n",
    "    \n",
    "    return speech_topics_df\n",
    "\n",
    "\n",
    "all_speeches_topics_df = append_topic(ldamodel=optimal_model, \n",
    "                                      corpus=bow_corpus, \n",
    "                                      speeches=data_preprocessed, \n",
    "                                      ids=main_ids,\n",
    "                                      kw_dict=keywords_dict,\n",
    "                                      mapping = mapping)\n",
    "all_speeches_topics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Count</th>\n",
       "      <th>Prim_Topic</th>\n",
       "      <th>Prim_Topic_Name</th>\n",
       "      <th>Prim_Topic_Contrib</th>\n",
       "      <th>Prim_Topic_Keywords</th>\n",
       "      <th>Sec_Topic</th>\n",
       "      <th>Sec_Topic_Name</th>\n",
       "      <th>Sec_Topic_Contrib</th>\n",
       "      <th>Speech_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Judicial Nominations</td>\n",
       "      <td>0.76</td>\n",
       "      <td>vote,judge,nomination,senators,district,record...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Common Phrases</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1080099024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>Great Nation</td>\n",
       "      <td>0.54</td>\n",
       "      <td>history,great,nation,day,american,live,first,w...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Judicial System</td>\n",
       "      <td>0.16</td>\n",
       "      <td>1080165561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Military</td>\n",
       "      <td>0.28</td>\n",
       "      <td>veterans,service,serve,va,military,honor,men_w...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Crime and Immigration</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1090156218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Random Verbs 2</td>\n",
       "      <td>0.44</td>\n",
       "      <td>think,want,come,know,get,issue,talk,way,see,co...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Random Verbs</td>\n",
       "      <td>0.31</td>\n",
       "      <td>1060121740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>Natural Disasters</td>\n",
       "      <td>0.39</td>\n",
       "      <td>emergency,home,help,texas,state,florida,flood,...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Federal Assistance Programs</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1100177577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic_Count  Prim_Topic       Prim_Topic_Name  Prim_Topic_Contrib  \\\n",
       "0          2.0         8.0  Judicial Nominations                0.76   \n",
       "1         10.0        35.0          Great Nation                0.54   \n",
       "2          8.0         1.0              Military                0.28   \n",
       "3          6.0        26.0        Random Verbs 2                0.44   \n",
       "4          7.0        19.0     Natural Disasters                0.39   \n",
       "\n",
       "                                 Prim_Topic_Keywords  Sec_Topic  \\\n",
       "0  vote,judge,nomination,senators,district,record...        9.0   \n",
       "1  history,great,nation,day,american,live,first,w...        5.0   \n",
       "2  veterans,service,serve,va,military,honor,men_w...        0.0   \n",
       "3  think,want,come,know,get,issue,talk,way,see,co...        4.0   \n",
       "4  emergency,home,help,texas,state,florida,flood,...       20.0   \n",
       "\n",
       "                Sec_Topic_Name  Sec_Topic_Contrib   Speech_id  \n",
       "0               Common Phrases               0.20  1080099024  \n",
       "1              Judicial System               0.16  1080165561  \n",
       "2        Crime and Immigration               0.21  1090156218  \n",
       "3                 Random Verbs               0.31  1060121740  \n",
       "4  Federal Assistance Programs               0.30  1100177577  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_speeches_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speeches_topics_df.to_pickle(outdata_path + 'speeches_topics_gender_' + str(num_topics))\n",
    "# all_speeches_topics_df = pd.read_pickle(outdata_path+'speeches_topics_'+str(num_topics))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick one speech per document with the highest score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting n top speeches per topic\n",
    "top_speeches = 1\n",
    "top_speeches_df = pd.DataFrame()\n",
    "\n",
    "all_speeches_topics_df_grpd = all_speeches_topics_df.groupby('Prim_Topic')\n",
    "\n",
    "for i, grp in all_speeches_topics_df_grpd:\n",
    "    top_speeches_df = pd.concat([top_speeches_df, grp.sort_values(by='Prim_Topic_Contrib', ascending=False).head(top_speeches)], axis=0)\n",
    "\n",
    "top_speeches_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_speeches_topics_df.to_pickle(outdata_path + 'topics_summary_' + str(num_topics))\n",
    "# topics_df = pd.read_pickle(outdata_path+'topics_summary_'+str(num_topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic number:  0.0\n",
      "Topic contribution: 0.82\n",
      "Keywords: \n",
      " drug,crime,border,immigration,gun,violence,act,mexico,law_enforcement,victims\n",
      "Speech: \n",
      " Madam President. I rise today to speak about the need for hate crimes legislation. On May 1. 2003. Senator KENNEDY and I introduced the Local Law Enforcement Enhancement Act. a bill that would add new categories to current hate crimes law. sending a signal that violence of any kind is unacceptable in our society. On January 14. 1999. in El Dorado. CA. Thomas Gary. 38. died after being run over by a truck and shot with a shot gun. The assailant claimed that Gary had made a pass at him. I believe that Governments first duty is to defend its citizens. to defend them against the harms that come out of hate. The Local Law Enforcement Enhancement Act is a symbol that can become substance. I believe that by passing this legislation and changing current law. we can change hearts and minds as well.\n",
      "--------------------------------------------------\n",
      "Topic number:  1.0\n",
      "Topic contribution: 0.73\n",
      "Keywords: \n",
      " veterans,service,serve,va,military,honor,men_women,country,families,sacrifice\n",
      "Speech: \n",
      " Mr. President. I feel that It is very Important that our Nation continues its firm commitment to those individuals and their families who have served in the Armed Forces and made us the great Nation that we are today. As this population becomes older. they are unfortunately finding that they need a wider range of health services. some of which are simply not available under Medicare. These individuals made a commitment to their Nation trusting that when they needed help the Nation would honor that commitment. The bill that I am recommending today. would ensure the highest possible quality of - care for these dedicated oitizens and their families. who gave so much for us. I ask unanimous consent that the text of my bill be printed in the RECORD.\n",
      "--------------------------------------------------\n",
      "Topic number:  2.0\n",
      "Topic contribution: 0.84\n",
      "Keywords: \n",
      " water,land,environmental,forest,project,national,public,area,environment,park\n",
      "Speech: \n",
      " Mr. Speaker. I move to suspend the rules and pass the Senate bill to provide for the expansion of the Eagles Nest Wilderness within the Arapaho National Forest and the White River National Forest. CO. to include land known as the Slate Creek Addition.\n",
      "--------------------------------------------------\n",
      "Topic number:  3.0\n",
      "Topic contribution: 0.89\n",
      "Keywords: \n",
      " vote,congress,political,republican,public,party,democratic,house,campaign,election\n",
      "Speech: \n",
      " Right. But there was an election between a Democrat. Frank McCloskey. an incumbent. and a challenger. Rick McIntyre. and after that election. there was a count. And what did that count show?\n",
      "--------------------------------------------------\n",
      "Topic number:  4.0\n",
      "Topic contribution: 0.95\n",
      "Keywords: \n",
      " get,money,want,know,dont,tell,back,come,let,pay\n",
      "Speech: \n",
      " It sounds to me. for instance. if you were a guy who decided that what you want to do is parlay your $4 a week by going and buying four lottery tickets a week. if you actually got lucky and it paid off. you would still be a loser out of all of this because the Democrats are going to take it all away from you after you have won the lottery.\n",
      "--------------------------------------------------\n",
      "Topic number:  5.0\n",
      "Topic contribution: 0.97\n",
      "Keywords: \n",
      " law,right,court,case,constitution,constitutional,judge,legal,federal,supreme_court\n",
      "Speech: \n",
      " \"Nor shall any person be subject for the same offense to be twice put in jeopardy of life or limb. nor shall be compelled in any criminal case to be a witness against himself. nor be deprived of life. liberty. or property. without due process of law. nor shall private property be taken for public use. without just compensation.\"\n",
      "--------------------------------------------------\n",
      "Topic number:  6.0\n",
      "Topic contribution: 0.80\n",
      "Keywords: \n",
      " fire,ship,port,navy,haiti,flag,coast_guard,officer,guam,beach\n",
      "Speech: \n",
      " Mr. Speaker. I move to suspend the rules and pass the bill to amend section 700 of title 18. United States Code. to protect the physical integrity of the flag. as amended.\n",
      "--------------------------------------------------\n",
      "Topic number:  7.0\n",
      "Topic contribution: 0.72\n",
      "Keywords: \n",
      " military,war,iraq,troop,defense,force,army,soldier,afghanistan,general\n",
      "Speech: \n",
      " For the indefinite future. we are asking them to endure this hostile fire. And from time to time they have to drop live ordnance to protect themselves in fulfillment of this containment mission over Iraq.\n",
      "--------------------------------------------------\n",
      "Topic number:  8.0\n",
      "Topic contribution: 0.98\n",
      "Keywords: \n",
      " vote,judge,nomination,senators,district,record,present,ms,confirm,district_columbia\n",
      "Speech: \n",
      " Mr. Speaker. on June 3. 2015 I was absent for recorded votes #274 through #295 due to the passing of my mother. I would like to reflect how I would have voted if I were here: On Roll Call #274 I would have voted No. On Roll Call #275 I would have voted No. On Roll Call #276 I would have voted Yes. On Roll Call #277 I would have voted Yes. On Roll Call #278 I would have voted No. On Roll Call #279 I would have voted No. On Roll Call #280 I would have voted Yes. On Roll Call #281 I would have voted Yes. On Roll Call #282 I would have voted No. On Roll Call #283 I would have voted Yes. On Roll Call #284 I would have voted Yes. On Roll Call #285 I would have voted Yes. On Roll Call #286 I would have voted Yes. On Roll Call #287 I would have voted No. On Roll Call #288 I would have voted Yes. On Roll Call #289 I would have voted No. On Roll Call #290 I would have voted Yes. On Roll Call #291 I would have voted No. On Roll Call #292 I would have voted No. On Roll Call #293 I would have voted No. On Roll Call #294 I would have voted No. On Roll Call #295 I would have voted No.\n",
      "--------------------------------------------------\n",
      "Topic number:  9.0\n",
      "Topic contribution: 0.98\n",
      "Keywords: \n",
      " house,committee,resolution,rule,ask_unanimous_consent,follow,order,may,hear,members\n",
      "Speech: \n",
      " Mr. President. I ask unanimous consent that when the Senate completes its business today. it stand in adjournment under the provisions of H. Con. Res. 483 until 10 a.m. on Thursday. November 9. and that following the prayer and the pledge. the Senate stand in adjournment until Monday. November 13. at 2 p.m. I further ask that notwithstanding the adjournment of the Senate on Novembei 9. Senators be permitted to introduce bills and submit statements and the Senate receive messages until 10:3C a.m. on November 9. . I further ask that following the prayer and the pledge on Monday. November 13. the morning hour be deemedtc have expired. the Journal of the proceedings be approved to date. the time for the two leaders be reserved. and the Senate proceed to a period of morning business. with Senators permitted tc speak therein for up to 10 minutes each.\n",
      "--------------------------------------------------\n",
      "Topic number:  10.0\n",
      "Topic contribution: 0.91\n",
      "Keywords: \n",
      " government,peace,freedom,israel,must,soviet,democracy,jewish,continue,world\n",
      "Speech: \n",
      " Mr. Speaker. on November 17 of last year. many of my colleagues in the House joined me in the fight against the Soviet Governments unjust treatment of Ukrainian human rights activIsts. At that time. the members of the Ukrainian Helsinki Monitoring Group. who have tried to promote basic human rights for Ukrainian citizens. were being subjected to harassment. arrest and persecution because of their personal beliefs. I would like to remind my colleagues that these noble people arc still being persecuted and oppressed by the Soviet authorities. Although this Soviet tyranny over the Ukraine continues today. it has not succeeded in crushing the independent spirit of their citizens. who stubbornly resist the attempted obliteration of their linguistic. ethnic and religious identities. The plight of these and all Ukrainian people may only be bettered by the continued attention of the free worlds leaders and press. Only when Soviet policies are revealed and repudiated by the rest of the civilized world will these authorities make concessions to humanitarian principles. The Soviet Union must be made to realize that it will be held accountable for its denial of basic human rights in the Ukraine. I sincerely hope that all my colleagues will support the efforts of the Ukrainian people to resist russification policies and to reachieve independence. It is fitting that we. as Americans and as compassionate people. pause to rededicate our commitment to human rights In the Ukraine.e\n",
      "--------------------------------------------------\n",
      "Topic number:  11.0\n",
      "Topic contribution: 0.78\n",
      "Keywords: \n",
      " women,medical,care,health,doctor,patients,hospital,abortion,service,access\n",
      "Speech: \n",
      " So this bill then has an optout of performing any abortion services. including counseling or referral? Does. this bill do that? It opts out performing any abortion services. counseling or referral?\n",
      "--------------------------------------------------\n",
      "Topic number:  12.0\n",
      "Topic contribution: 0.96\n",
      "Keywords: \n",
      " report,information,department,intelligence,government,commission,office,committee,administration,security\n",
      "Speech: \n",
      " As I understand. the Director of the Central Intelligence Agency would be called upon. who Is in charge of all intelligence gathering for the administration. So. he would have the Defense Intelligence Agency. the National Security Agency. and other agencies that are involved in intelligence gathering involved in this activity. as I understand it.\n",
      "--------------------------------------------------\n",
      "Topic number:  13.0\n",
      "Topic contribution: 0.98\n",
      "Keywords: \n",
      " community,service,national,recognize,award,association,center,city,honor,year\n",
      "Speech: \n",
      " Mr. President. I call attention to a very special event to be celebrated in Bay City. Mich.. in midFebruary. The Bay Area Chamber of Commerce will be celebrating its 100th anniversary: 100 years of continuous and industrious community service. Founded in February of 1883 by a group of dedicated and conscientious business people. the Bay Area Chamber of Commerce distinguishes itself by being one of the oldest such organizations in the Nation. For 100 years it has continuously provided a forum for Bay Area business people so they can better the economic climate and serve their community. citizens. and social agencies in countless ways. I congratulate the members of the Bay Area Chamber of Commerce on their fine achievements and wish them another century of valued service to their community.e\n",
      "--------------------------------------------------\n",
      "Topic number:  14.0\n",
      "Topic contribution: 0.55\n",
      "Keywords: \n",
      " farm,farmers,agriculture,food,agricultural,program,price,rural,arkansas,market\n",
      "Speech: \n",
      " Mr. Speaker. I rise in support of this legislation by my committee today to add a supplemental appropriation with which the Commodity Credit Corporation can continue its operation. The rice farmers of America are facing the same depressed prices as all farmers. However. many are suffering even more because they are unable to participate in the Commodity Credit loan program or benefit from its traditional price support rule because of an unintended loophole in the current law by which only about 30 percent of the rice farmers in Arkansas can participate. I have introduced a bill which will change this condition and allow all farmers to participate equally. It is H.R. 5399. And I have arranged for a meeting with the Secretary of Agriculture. Mr. Block. tomorrow in order to try to pursuade the administration to support this bill. In essense what is happening Is that because of low prices farmers have no market for their rice crop. In my State many of the rice farmers are forced to sell that crop in order to be provided enough capital with which to farm for the 1982 crop year. For those farmers who are excluded from participation in the Commodity Credit Corporation loan program. they are forced to sell their crop far below the low market prices which are available through the program. In effect. they are forced into bankruptcy. I would urge the committee. the Congress. and the Members who are concerned about fairness and equity in agriculture to support this bill which will eliminate this loophole in the law.\n",
      "--------------------------------------------------\n",
      "Topic number:  15.0\n",
      "Topic contribution: 0.86\n",
      "Keywords: \n",
      " job,workers,economy,labor,create,economic,american,employees,americans,help\n",
      "Speech: \n",
      " Mr. Speaker. in closing. I would once again urge my colleagues to support the AMERICA Works Act. At a time when unemployment is high. we need to do everything we can to enable our workers not only to be trained. but to be able to utilize that training anywhere in our country. I yield back the balance of my time.\n",
      "--------------------------------------------------\n",
      "Topic number:  16.0\n",
      "Topic contribution: 0.85\n",
      "Keywords: \n",
      " legislation,act,provision,require,congress,federal,provide,process,section,change\n",
      "Speech: \n",
      " Mr. President. I am pleased to Introduce legislation today with Senator LLOYD BENTSEN to improve the 1981 incentive stock options rules. I am also delighted that. JIm Jons and BILL FRENzEL have introduced the companion legislation in the House of Representatives. H.R. The four of us were the prime sponsors of the original incentive stock options legislation enacted in 1981. We have decided to join together again to introduce this legislation because we believe that changes are needed to insure that the incentive stock options law achieves the purposes originally intended.\n",
      "--------------------------------------------------\n",
      "Topic number:  17.0\n",
      "Topic contribution: 0.53\n",
      "Keywords: \n",
      " children,program,families,welfare,child,poor,family,poverty,live,care\n",
      "Speech: \n",
      " Mr. Chairman. I am pleased to join with my colleagues. Representatives KELLY and COHEN. to introduce this amendment to increase the summer food program for children by $3 million. Across the country. one of every five children is at risk of going hungry. In Nevada. more than 233.000 children qualify for free or reduced lunch. That means that 54 percent of Nevadas students come from lowincome households that struggle with hunger. While these children can eat free and reducedprice lunch during the school year. the vast majority are left without adequate nutrition during the summer. The Summer EBT program is a pilot program that helps fill this gap by providing eligible families with additional SNAP benefits during the summer months. It works. In 2012. it served almost 67.000 children who might have otherwise gone hungry. The participation in this program is dramatically higher than in other programs. serving up to 75 percent of eligible children. That is why I believe that we should meet the Presidents budget request and increase funding to feed as many hungry children as possible. A vacation from school shouldnt mean a hungry child.\n",
      "--------------------------------------------------\n",
      "Topic number:  18.0\n",
      "Topic contribution: 0.96\n",
      "Keywords: \n",
      " amendment,chairman,gentleman,committee,offer,vote,want,amendments,thank,distinguish\n",
      "Speech: \n",
      " Mr. Chairman. I rise in opposition to the amendment. The gentleman from Wisconsin had objected because he asked the gentleman or was seeking to have the gentleman from North Carolina yield to the gentleman from Wisconsin because I was about prepared to accept his amendment. After hearing his explanation. I am not so sure. so I will not accept the amendment but let it go its course.\n",
      "--------------------------------------------------\n",
      "Topic number:  19.0\n",
      "Topic contribution: 0.85\n",
      "Keywords: \n",
      " emergency,home,help,texas,state,florida,flood,disaster,damage,communities\n",
      "Speech: \n",
      " Mr. Speaker. Americans are still shaken by this weeks Amtrak derailment that took the lives of seven people and left more than 200 injured. Our thoughts and prayers are with the families who have suffered a loss.\n",
      "--------------------------------------------------\n",
      "Topic number:  20.0\n",
      "Topic contribution: 0.84\n",
      "Keywords: \n",
      " program,fund,provide,million,house,service,include,assistance,federal,grant\n",
      "Speech: \n",
      " I believe that the voucher and certificate 811 program would be more beneficial to those with significant disabilities if nonprofit organizations with significant experience providing such services would be fully engaged. working with housing authorities. And. I believe that HUD should give favorable treatment to applications providing for substantial assistance by nonprofit organizations with experience in helping the severely disabled.\n",
      "--------------------------------------------------\n",
      "Topic number:  21.0\n",
      "Topic contribution: 0.87\n",
      "Keywords: \n",
      " school,education,students,college,children,program,educational,teachers,young,learn\n",
      "Speech: \n",
      " Mr. President. I rise today to introduce the Providing Resources Early for Kids Act of 2013the PREK Act. Research shows that quality early education is foundational for success in school and in life.\n",
      "--------------------------------------------------\n",
      "Topic number:  22.0\n",
      "Topic contribution: 0.76\n",
      "Keywords: \n",
      " trade,company,industry,market,american,export,foreign,products,countries,import\n",
      "Speech: \n",
      " makes the flawed assumption that the reason we have such a large trade deficit is that our trading partners have closed their borders to our products and participate in unfair trade practices against us.\n",
      "--------------------------------------------------\n",
      "Topic number:  23.0\n",
      "Topic contribution: 0.98\n",
      "Keywords: \n",
      " children,health,child,disease,treatment,live,parent,national,research,help\n",
      "Speech: \n",
      " Mr. Speaker. I rise today to recognize May as National Syringomyelia Awareness Month. with the hope that increased awareness of this disorder will bring a cu re. Syringomyelia. often referred to as SM. is a progressive disease of the spinal cord and has no known cure. Over 40.000 Americans are affected by SM and those individuals can suffer from chronic pain and even paralysis. It is imperative that we educate the public and provide resources to the medical community in order to find a cure for this disease. Mr. Speaker. I ask all my colleagues to join me not just today but every day in helping to raise awareness to Syringomyelia.\n",
      "--------------------------------------------------\n",
      "Topic number:  24.0\n",
      "Topic contribution: 0.97\n",
      "Keywords: \n",
      " serve,service,family,honor,dr,member,life,career,university,john\n",
      "Speech: \n",
      " Mr. Speaker. one of Clevelands finest citizens. Lanette Flower. has passed away. She was a person of great quality. Her husband. Dr. John Flower. recently retired as president of Cleveland State University. He did an outstanding job. His wife was always by his side. The following is the article which memcrialized her life: LhNVTm S. FLOWER. 62. WiYE O\" CSU\n",
      "--------------------------------------------------\n",
      "Topic number:  25.0\n",
      "Topic contribution: 0.70\n",
      "Keywords: \n",
      " transportation,safety,project,system,highway,construction,air,build,airport,truck\n",
      "Speech: \n",
      " Mr. Speaker. I ask unanimous consent for the immediate consideration of the bill to designate the Federal building located at 310 New Bern Avenue in Raleigh. North Carolina. as the \"Terry- Sanford Federal Building.\"\n",
      "--------------------------------------------------\n",
      "Topic number:  26.0\n",
      "Topic contribution: 0.97\n",
      "Keywords: \n",
      " think,want,come,know,get,issue,talk,way,see,country\n",
      "Speech: \n",
      " Mr. President. if I could talk back to the respected leader. I thank him for bringing it forward. I do think it is important we work through eight bills before the recess begins. and I hope over the next couple of hours he and the distinguished Senator from South Carolina can reach some resolve that is an accommodation and we can move through this. .I thank the Senator very much for his patience. I suggest the absence of a quorum. -\n",
      "--------------------------------------------------\n",
      "Topic number:  27.0\n",
      "Topic contribution: 0.90\n",
      "Keywords: \n",
      " world,nations,international,policy,countries,nuclear,must,administration,agreement,security\n",
      "Speech: \n",
      " Mr. Speaker. I rise today against this measure to restrain President Obama from lifting sanctions and to support the Iran dealthe most important step that we could take to secure the future of this planet by stopping Irans nuclear program for 15 years. A nuclear Iran is an unacceptable danger. Irans support of terror and aggression throughout the world. its stated threats to Israel. and the nuclear arms race they would trigger are the reasons the worlds major powers came together to put crushing sanctions on Iran in the first place. Currently. Iran can produce enough material for a nuclear weapon in 2 to 3 months. Under this deal. Iran must take several unprecedented steps that would prevent them from having a nuclear weapon in 15 years. This deal goes further than any agreement in history by including inspections of Irans entire uranium enrichment supply chain for up to 25 years. Additionally. Iran will be subject to inspections forever under the additional protocol. It is those crushing economic sanctions that brought Iran to the table to finally accept the nuclear deal. What is critical to remember is that our terrorism sanctions still remain in place. and if a military strike is necessary. the U.S. will have the time and intelligence to intervene but without the threat of a nuclear bomb for 15 years. In contrast. without this deal. sanctions will be lifted anyway. and we will be left with nothing but fear. uncertainty. and an unfettered Iran. Considering the anxiety of recent years. when the prospect of a military strike on Iran felt imminent. this deal is a welcome alternative. and the risks of rejecting it are too great. For the sake of our security. the security of our allies. and our position as a trustworthy global leader. I urge my colleagues to support the deal and to reject this resolution.\n",
      "--------------------------------------------------\n",
      "Topic number:  28.0\n",
      "Topic contribution: 0.75\n",
      "Keywords: \n",
      " bank,loan,financial,credit,small_business,market,business,company,small_businesses,capital\n",
      "Speech: \n",
      " Mr. Speaker. I rise to introduce a bill to amend the Internal Revenue Code of 1986 to prevent small businesses investment companies from providing leveraged buyout and other financing to business which have a significant amount of assets. Mr. Speaker. small business investment companies are private. Government sponsored entities. These Government sponsored E 875\n",
      "--------------------------------------------------\n",
      "Topic number:  29.0\n",
      "Topic contribution: 0.81\n",
      "Keywords: \n",
      " energy,oil,price,fuel,production,power,natural_gas,use,supply,gas\n",
      "Speech: \n",
      " Mr. President. it is important that Congress make available all possible options for. refiners to ensure compliance with the renewable fuels standard and decrease chances for gasoline price and supply volatility. One such option for meeting the renewable fuels standard that has shown promise is ethyl tertiary butyl ether ETBE. ETBE is a Highoctane. lowvapor pressure. gasolineblending component produced from a combination of ethanol and butane. Because both of these raw materials are produced in abundance domestically. ETBE will help expand US gasoline supplies. moderating possible gasoline price volatility. ETBE is fully fungible with gasoline. This allows ETBE to be blended into gasoline at any point in the gasoline logistical chain and transported in gasoline pipelines to regions of the country where it is more costly to transport and blend ethanol into gasoline. More-\n",
      "--------------------------------------------------\n",
      "Topic number:  30.0\n",
      "Topic contribution: 0.72\n",
      "Keywords: \n",
      " research,technology,new,science,space,program,test,system,national,use\n",
      "Speech: \n",
      " Mr. Speaker. Mars is an intriguing planet. Mars is more like Earth than any of the planets in our solar system. As a result. Mars has capturedthe imagination of generations of scientists. astronomers. and space enthusiasts. A valuable speech about the Red Planet was given this summer by Arnold Aldrich. associate administrator of the Office of Aeronautics. Exploration and Technology for NASA during a conference in Williamsburg. VA. The speech examines the reasons why Mars intrigues us to such an extent and focuses on current and future exploration initiatives of the planet Mars. I would also like to point out to my colleagues that Amie Aldrich recently left the Office of Aerospace. Exploration and Technology to become associate administrator for the Office of Space Systems Development at NASA. where he will continue to provide expertise and direction to our Nations space program.\n",
      "--------------------------------------------------\n",
      "Topic number:  31.0\n",
      "Topic contribution: 0.88\n",
      "Keywords: \n",
      " state,washington,colorado,california,alaska,indian,minnesota,nevada,governor,native\n",
      "Speech: \n",
      " I announce that the Senator from Montana . the Senator from Delaware . the Senator from Nevada . the Senator from Arizona . the Senator from Colorado . the Senator from Hawaif . the Senator from Montana\n",
      "--------------------------------------------------\n",
      "Topic number:  32.0\n",
      "Topic contribution: 0.94\n",
      "Keywords: \n",
      " budget,spend,billion,cut,deficit,congress,debt,year,tax,vote\n",
      "Speech: \n",
      " So that if we rise above the democratically passed House budget resolution. we would be not only sending the wrong signal. but in effect falsely giving hope where there will be none.\n",
      "--------------------------------------------------\n",
      "Topic number:  33.0\n",
      "Topic contribution: 0.82\n",
      "Keywords: \n",
      " percent,cost,increase,million,year,number,billion,rate,less,level\n",
      "Speech: \n",
      " They have not been. because. again based on the Cost Analysis Improvement Groups conclusion. there appears to be over $6 billion in additional costs on the BlB that are over and above the current Air Force estimates.\n",
      "--------------------------------------------------\n",
      "Topic number:  34.0\n",
      "Topic contribution: 0.86\n",
      "Keywords: \n",
      " tax,pay,medicare,benefit,plan,social_security,income,cost,insurance,seniors\n",
      "Speech: \n",
      " Mr. Speaker. in 2003. Republicans said they were overhauling Medicare. but all they succeeded in doing was creating a prescription drug doughnut hole that. in 2009 alone. forced 63.000 Maryland seniors to pay thousands of dollars out of pocket. forcing many to choose between buying the prescription drugs they need or purchasing food. The Nations seniors shouldnt be forced to make such a choice. Thats why. under the new health care law. we are dedicated to closing the doughnut hole once and for all. Today. June 10. $250 checks are being mailed out to 80.000 eligible seniors as a first step to reducing the financial burden faced by seniors. Then next year there will be a 50 percent discount on prescription drugs in the doughnut hole. Mr. Speaker. the first of many benefits under the health law that my Republican colleagues opposed and now hope to repeal is on the way. Our seniors and the rest of the country cant afford to go back to a broken system controlled by insurance companies with coverage gaps. denied care. and skyrocketing costs.\n",
      "--------------------------------------------------\n",
      "Topic number:  35.0\n",
      "Topic contribution: 0.91\n",
      "Keywords: \n",
      " history,great,nation,day,american,live,first,world,americans,life\n",
      "Speech: \n",
      " I rise today to congratulate the Detroit Hockey Red Wings. The Detroit Red Wings. the 2008 National Hockey League champions for the Stanley Cup. We are most proud of you. To the coaches. the players. the Bitch family. thank you for a wonderful. exciting season. The Detroit Red Wings. the Stanley Cup champions for 2008. You have brought joy and cheer and adventure to - all of us. Good luck to you. Enjoy your time off. And have another wonderful season as we march to the 2009 Stanley Cup. Congratulations. Red Wings.\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(top_speeches_df.shape[0]):\n",
    "    print(\"Topic number: \", top_speeches_df.Prim_Topic[i])\n",
    "    print(\"Topic contribution: {:.2f}\".format(top_speeches_df.Prim_Topic_Contrib[i]))\n",
    "    print(\"Keywords: \\n\", top_speeches_df.Prim_Topic_Keywords[i])\n",
    "    print(\"Speech: \\n\", main_data[main_ids.index(top_speeches_df.Speech_id[i])])\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primary and secondary topic distribution in the speech file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = pd.DataFrame(index=range(num_topics))\n",
    "# Number of Documents for Each Topic\n",
    "prim_topic_counts = all_speeches_topics_df['Prim_Topic'].value_counts().sort_index()\n",
    "sec_topic_counts = all_speeches_topics_df['Sec_Topic'].value_counts().sort_index()\n",
    "# Percentage of Documents for Each Topic\n",
    "prim_topic_share = round(prim_topic_counts/len(main_data), 2)\n",
    "prim_topic_share.name = 'Prim_Topic_Contr'\n",
    "sec_topic_share = round(sec_topic_counts/len(main_data), 2)\n",
    "sec_topic_share.name = 'Sec_Topic_Contr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62716, 1.0000000000000002, 61960, 1.01)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df_joined= topics_df.join(prim_topic_counts)\\\n",
    "                    .join(prim_topic_share)\\\n",
    "                    .join(sec_topic_counts)\\\n",
    "                    .join(sec_topic_share)\\\n",
    "                    .join(pd.DataFrame.from_dict(keywords_dict, orient='index'))\n",
    "topics_df_joined.reset_index(inplace=True)\n",
    "topics_df_joined.columns = ['Topic_Num', \"Prim_Cnt\", \"Prim_Share\", \"Sec_Cnt\", \"Sec_Share\"] + ['kw'+str(i) for i in range(num_words)]\n",
    "topics_df_joined.Prim_Cnt.sum(), topics_df_joined.Prim_Share.sum(), topics_df_joined.Sec_Cnt.sum(), topics_df_joined.Sec_Share.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Prim_Cnt</th>\n",
       "      <th>Prim_Share</th>\n",
       "      <th>Sec_Cnt</th>\n",
       "      <th>Sec_Share</th>\n",
       "      <th>kw0</th>\n",
       "      <th>kw1</th>\n",
       "      <th>kw2</th>\n",
       "      <th>kw3</th>\n",
       "      <th>kw4</th>\n",
       "      <th>kw5</th>\n",
       "      <th>kw6</th>\n",
       "      <th>kw7</th>\n",
       "      <th>kw8</th>\n",
       "      <th>kw9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>9437</td>\n",
       "      <td>0.15</td>\n",
       "      <td>6956</td>\n",
       "      <td>0.11</td>\n",
       "      <td>think</td>\n",
       "      <td>want</td>\n",
       "      <td>come</td>\n",
       "      <td>know</td>\n",
       "      <td>get</td>\n",
       "      <td>issue</td>\n",
       "      <td>talk</td>\n",
       "      <td>way</td>\n",
       "      <td>see</td>\n",
       "      <td>country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>6003</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5026</td>\n",
       "      <td>0.08</td>\n",
       "      <td>amendment</td>\n",
       "      <td>chairman</td>\n",
       "      <td>gentleman</td>\n",
       "      <td>committee</td>\n",
       "      <td>offer</td>\n",
       "      <td>vote</td>\n",
       "      <td>want</td>\n",
       "      <td>amendments</td>\n",
       "      <td>thank</td>\n",
       "      <td>distinguish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4082</td>\n",
       "      <td>0.07</td>\n",
       "      <td>2830</td>\n",
       "      <td>0.05</td>\n",
       "      <td>house</td>\n",
       "      <td>committee</td>\n",
       "      <td>resolution</td>\n",
       "      <td>rule</td>\n",
       "      <td>ask_unanimous_consent</td>\n",
       "      <td>follow</td>\n",
       "      <td>order</td>\n",
       "      <td>may</td>\n",
       "      <td>hear</td>\n",
       "      <td>members</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>3989</td>\n",
       "      <td>0.06</td>\n",
       "      <td>4098</td>\n",
       "      <td>0.07</td>\n",
       "      <td>legislation</td>\n",
       "      <td>act</td>\n",
       "      <td>provision</td>\n",
       "      <td>require</td>\n",
       "      <td>congress</td>\n",
       "      <td>federal</td>\n",
       "      <td>provide</td>\n",
       "      <td>process</td>\n",
       "      <td>section</td>\n",
       "      <td>change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>3375</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2709</td>\n",
       "      <td>0.04</td>\n",
       "      <td>serve</td>\n",
       "      <td>service</td>\n",
       "      <td>family</td>\n",
       "      <td>honor</td>\n",
       "      <td>dr</td>\n",
       "      <td>member</td>\n",
       "      <td>life</td>\n",
       "      <td>career</td>\n",
       "      <td>university</td>\n",
       "      <td>john</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>2940</td>\n",
       "      <td>0.05</td>\n",
       "      <td>2712</td>\n",
       "      <td>0.04</td>\n",
       "      <td>community</td>\n",
       "      <td>service</td>\n",
       "      <td>national</td>\n",
       "      <td>recognize</td>\n",
       "      <td>award</td>\n",
       "      <td>association</td>\n",
       "      <td>center</td>\n",
       "      <td>city</td>\n",
       "      <td>honor</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>2883</td>\n",
       "      <td>0.05</td>\n",
       "      <td>3096</td>\n",
       "      <td>0.05</td>\n",
       "      <td>history</td>\n",
       "      <td>great</td>\n",
       "      <td>nation</td>\n",
       "      <td>day</td>\n",
       "      <td>american</td>\n",
       "      <td>live</td>\n",
       "      <td>first</td>\n",
       "      <td>world</td>\n",
       "      <td>americans</td>\n",
       "      <td>life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2493</td>\n",
       "      <td>0.04</td>\n",
       "      <td>3491</td>\n",
       "      <td>0.06</td>\n",
       "      <td>get</td>\n",
       "      <td>money</td>\n",
       "      <td>want</td>\n",
       "      <td>know</td>\n",
       "      <td>dont</td>\n",
       "      <td>tell</td>\n",
       "      <td>back</td>\n",
       "      <td>come</td>\n",
       "      <td>let</td>\n",
       "      <td>pay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>2399</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1965</td>\n",
       "      <td>0.03</td>\n",
       "      <td>budget</td>\n",
       "      <td>spend</td>\n",
       "      <td>billion</td>\n",
       "      <td>cut</td>\n",
       "      <td>deficit</td>\n",
       "      <td>congress</td>\n",
       "      <td>debt</td>\n",
       "      <td>year</td>\n",
       "      <td>tax</td>\n",
       "      <td>vote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2092</td>\n",
       "      <td>0.03</td>\n",
       "      <td>2460</td>\n",
       "      <td>0.04</td>\n",
       "      <td>program</td>\n",
       "      <td>fund</td>\n",
       "      <td>provide</td>\n",
       "      <td>million</td>\n",
       "      <td>house</td>\n",
       "      <td>service</td>\n",
       "      <td>include</td>\n",
       "      <td>assistance</td>\n",
       "      <td>federal</td>\n",
       "      <td>grant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>1955</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1834</td>\n",
       "      <td>0.03</td>\n",
       "      <td>world</td>\n",
       "      <td>nations</td>\n",
       "      <td>international</td>\n",
       "      <td>policy</td>\n",
       "      <td>countries</td>\n",
       "      <td>nuclear</td>\n",
       "      <td>must</td>\n",
       "      <td>administration</td>\n",
       "      <td>agreement</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1719</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1178</td>\n",
       "      <td>0.02</td>\n",
       "      <td>government</td>\n",
       "      <td>peace</td>\n",
       "      <td>freedom</td>\n",
       "      <td>israel</td>\n",
       "      <td>must</td>\n",
       "      <td>soviet</td>\n",
       "      <td>democracy</td>\n",
       "      <td>jewish</td>\n",
       "      <td>continue</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1609</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1932</td>\n",
       "      <td>0.03</td>\n",
       "      <td>law</td>\n",
       "      <td>right</td>\n",
       "      <td>court</td>\n",
       "      <td>case</td>\n",
       "      <td>constitution</td>\n",
       "      <td>constitutional</td>\n",
       "      <td>judge</td>\n",
       "      <td>legal</td>\n",
       "      <td>federal</td>\n",
       "      <td>supreme_court</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>1608</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1448</td>\n",
       "      <td>0.02</td>\n",
       "      <td>tax</td>\n",
       "      <td>pay</td>\n",
       "      <td>medicare</td>\n",
       "      <td>benefit</td>\n",
       "      <td>plan</td>\n",
       "      <td>social_security</td>\n",
       "      <td>income</td>\n",
       "      <td>cost</td>\n",
       "      <td>insurance</td>\n",
       "      <td>seniors</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>1475</td>\n",
       "      <td>0.02</td>\n",
       "      <td>991</td>\n",
       "      <td>0.02</td>\n",
       "      <td>children</td>\n",
       "      <td>health</td>\n",
       "      <td>child</td>\n",
       "      <td>disease</td>\n",
       "      <td>treatment</td>\n",
       "      <td>live</td>\n",
       "      <td>parent</td>\n",
       "      <td>national</td>\n",
       "      <td>research</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1454</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1627</td>\n",
       "      <td>0.03</td>\n",
       "      <td>job</td>\n",
       "      <td>workers</td>\n",
       "      <td>economy</td>\n",
       "      <td>labor</td>\n",
       "      <td>create</td>\n",
       "      <td>economic</td>\n",
       "      <td>american</td>\n",
       "      <td>employees</td>\n",
       "      <td>americans</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1146</td>\n",
       "      <td>0.02</td>\n",
       "      <td>school</td>\n",
       "      <td>education</td>\n",
       "      <td>students</td>\n",
       "      <td>college</td>\n",
       "      <td>children</td>\n",
       "      <td>program</td>\n",
       "      <td>educational</td>\n",
       "      <td>teachers</td>\n",
       "      <td>young</td>\n",
       "      <td>learn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1205</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1008</td>\n",
       "      <td>0.02</td>\n",
       "      <td>water</td>\n",
       "      <td>land</td>\n",
       "      <td>environmental</td>\n",
       "      <td>forest</td>\n",
       "      <td>project</td>\n",
       "      <td>national</td>\n",
       "      <td>public</td>\n",
       "      <td>area</td>\n",
       "      <td>environment</td>\n",
       "      <td>park</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1015</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1529</td>\n",
       "      <td>0.02</td>\n",
       "      <td>report</td>\n",
       "      <td>information</td>\n",
       "      <td>department</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>government</td>\n",
       "      <td>commission</td>\n",
       "      <td>office</td>\n",
       "      <td>committee</td>\n",
       "      <td>administration</td>\n",
       "      <td>security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>910</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1270</td>\n",
       "      <td>0.02</td>\n",
       "      <td>military</td>\n",
       "      <td>war</td>\n",
       "      <td>iraq</td>\n",
       "      <td>troop</td>\n",
       "      <td>defense</td>\n",
       "      <td>force</td>\n",
       "      <td>army</td>\n",
       "      <td>soldier</td>\n",
       "      <td>afghanistan</td>\n",
       "      <td>general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>894</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1064</td>\n",
       "      <td>0.02</td>\n",
       "      <td>women</td>\n",
       "      <td>medical</td>\n",
       "      <td>care</td>\n",
       "      <td>health</td>\n",
       "      <td>doctor</td>\n",
       "      <td>patients</td>\n",
       "      <td>hospital</td>\n",
       "      <td>abortion</td>\n",
       "      <td>service</td>\n",
       "      <td>access</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>879</td>\n",
       "      <td>0.01</td>\n",
       "      <td>921</td>\n",
       "      <td>0.01</td>\n",
       "      <td>vote</td>\n",
       "      <td>judge</td>\n",
       "      <td>nomination</td>\n",
       "      <td>senators</td>\n",
       "      <td>district</td>\n",
       "      <td>record</td>\n",
       "      <td>present</td>\n",
       "      <td>ms</td>\n",
       "      <td>confirm</td>\n",
       "      <td>district_columbia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>843</td>\n",
       "      <td>0.01</td>\n",
       "      <td>979</td>\n",
       "      <td>0.02</td>\n",
       "      <td>drug</td>\n",
       "      <td>crime</td>\n",
       "      <td>border</td>\n",
       "      <td>immigration</td>\n",
       "      <td>gun</td>\n",
       "      <td>violence</td>\n",
       "      <td>act</td>\n",
       "      <td>mexico</td>\n",
       "      <td>law_enforcement</td>\n",
       "      <td>victims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>770</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1733</td>\n",
       "      <td>0.03</td>\n",
       "      <td>percent</td>\n",
       "      <td>cost</td>\n",
       "      <td>increase</td>\n",
       "      <td>million</td>\n",
       "      <td>year</td>\n",
       "      <td>number</td>\n",
       "      <td>billion</td>\n",
       "      <td>rate</td>\n",
       "      <td>less</td>\n",
       "      <td>level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>732</td>\n",
       "      <td>0.01</td>\n",
       "      <td>802</td>\n",
       "      <td>0.01</td>\n",
       "      <td>veterans</td>\n",
       "      <td>service</td>\n",
       "      <td>serve</td>\n",
       "      <td>va</td>\n",
       "      <td>military</td>\n",
       "      <td>honor</td>\n",
       "      <td>men_women</td>\n",
       "      <td>country</td>\n",
       "      <td>families</td>\n",
       "      <td>sacrifice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>727</td>\n",
       "      <td>0.01</td>\n",
       "      <td>536</td>\n",
       "      <td>0.01</td>\n",
       "      <td>energy</td>\n",
       "      <td>oil</td>\n",
       "      <td>price</td>\n",
       "      <td>fuel</td>\n",
       "      <td>production</td>\n",
       "      <td>power</td>\n",
       "      <td>natural_gas</td>\n",
       "      <td>use</td>\n",
       "      <td>supply</td>\n",
       "      <td>gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>654</td>\n",
       "      <td>0.01</td>\n",
       "      <td>918</td>\n",
       "      <td>0.01</td>\n",
       "      <td>bank</td>\n",
       "      <td>loan</td>\n",
       "      <td>financial</td>\n",
       "      <td>credit</td>\n",
       "      <td>small_business</td>\n",
       "      <td>market</td>\n",
       "      <td>business</td>\n",
       "      <td>company</td>\n",
       "      <td>small_businesses</td>\n",
       "      <td>capital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>593</td>\n",
       "      <td>0.01</td>\n",
       "      <td>748</td>\n",
       "      <td>0.01</td>\n",
       "      <td>emergency</td>\n",
       "      <td>home</td>\n",
       "      <td>help</td>\n",
       "      <td>texas</td>\n",
       "      <td>state</td>\n",
       "      <td>florida</td>\n",
       "      <td>flood</td>\n",
       "      <td>disaster</td>\n",
       "      <td>damage</td>\n",
       "      <td>communities</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>544</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1112</td>\n",
       "      <td>0.02</td>\n",
       "      <td>vote</td>\n",
       "      <td>congress</td>\n",
       "      <td>political</td>\n",
       "      <td>republican</td>\n",
       "      <td>public</td>\n",
       "      <td>party</td>\n",
       "      <td>democratic</td>\n",
       "      <td>house</td>\n",
       "      <td>campaign</td>\n",
       "      <td>election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>533</td>\n",
       "      <td>0.01</td>\n",
       "      <td>710</td>\n",
       "      <td>0.01</td>\n",
       "      <td>trade</td>\n",
       "      <td>company</td>\n",
       "      <td>industry</td>\n",
       "      <td>market</td>\n",
       "      <td>american</td>\n",
       "      <td>export</td>\n",
       "      <td>foreign</td>\n",
       "      <td>products</td>\n",
       "      <td>countries</td>\n",
       "      <td>import</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>481</td>\n",
       "      <td>0.01</td>\n",
       "      <td>746</td>\n",
       "      <td>0.01</td>\n",
       "      <td>research</td>\n",
       "      <td>technology</td>\n",
       "      <td>new</td>\n",
       "      <td>science</td>\n",
       "      <td>space</td>\n",
       "      <td>program</td>\n",
       "      <td>test</td>\n",
       "      <td>system</td>\n",
       "      <td>national</td>\n",
       "      <td>use</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>407</td>\n",
       "      <td>0.01</td>\n",
       "      <td>654</td>\n",
       "      <td>0.01</td>\n",
       "      <td>children</td>\n",
       "      <td>program</td>\n",
       "      <td>families</td>\n",
       "      <td>welfare</td>\n",
       "      <td>child</td>\n",
       "      <td>poor</td>\n",
       "      <td>family</td>\n",
       "      <td>poverty</td>\n",
       "      <td>live</td>\n",
       "      <td>care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>336</td>\n",
       "      <td>0.01</td>\n",
       "      <td>553</td>\n",
       "      <td>0.01</td>\n",
       "      <td>transportation</td>\n",
       "      <td>safety</td>\n",
       "      <td>project</td>\n",
       "      <td>system</td>\n",
       "      <td>highway</td>\n",
       "      <td>construction</td>\n",
       "      <td>air</td>\n",
       "      <td>build</td>\n",
       "      <td>airport</td>\n",
       "      <td>truck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>209</td>\n",
       "      <td>0.00</td>\n",
       "      <td>380</td>\n",
       "      <td>0.01</td>\n",
       "      <td>farm</td>\n",
       "      <td>farmers</td>\n",
       "      <td>agriculture</td>\n",
       "      <td>food</td>\n",
       "      <td>agricultural</td>\n",
       "      <td>program</td>\n",
       "      <td>price</td>\n",
       "      <td>rural</td>\n",
       "      <td>arkansas</td>\n",
       "      <td>market</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>135</td>\n",
       "      <td>0.00</td>\n",
       "      <td>365</td>\n",
       "      <td>0.01</td>\n",
       "      <td>fire</td>\n",
       "      <td>ship</td>\n",
       "      <td>port</td>\n",
       "      <td>navy</td>\n",
       "      <td>haiti</td>\n",
       "      <td>flag</td>\n",
       "      <td>coast_guard</td>\n",
       "      <td>officer</td>\n",
       "      <td>guam</td>\n",
       "      <td>beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>79</td>\n",
       "      <td>0.00</td>\n",
       "      <td>433</td>\n",
       "      <td>0.01</td>\n",
       "      <td>state</td>\n",
       "      <td>washington</td>\n",
       "      <td>colorado</td>\n",
       "      <td>california</td>\n",
       "      <td>alaska</td>\n",
       "      <td>indian</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>nevada</td>\n",
       "      <td>governor</td>\n",
       "      <td>native</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic_Num  Prim_Cnt  Prim_Share  Sec_Cnt  Sec_Share             kw0  \\\n",
       "26         26      9437        0.15     6956       0.11           think   \n",
       "18         18      6003        0.10     5026       0.08       amendment   \n",
       "9           9      4082        0.07     2830       0.05           house   \n",
       "16         16      3989        0.06     4098       0.07     legislation   \n",
       "24         24      3375        0.05     2709       0.04           serve   \n",
       "13         13      2940        0.05     2712       0.04       community   \n",
       "35         35      2883        0.05     3096       0.05         history   \n",
       "4           4      2493        0.04     3491       0.06             get   \n",
       "32         32      2399        0.04     1965       0.03          budget   \n",
       "20         20      2092        0.03     2460       0.04         program   \n",
       "27         27      1955        0.03     1834       0.03           world   \n",
       "10         10      1719        0.03     1178       0.02      government   \n",
       "5           5      1609        0.03     1932       0.03             law   \n",
       "34         34      1608        0.03     1448       0.02             tax   \n",
       "23         23      1475        0.02      991       0.02        children   \n",
       "15         15      1454        0.02     1627       0.03             job   \n",
       "21         21      1257        0.02     1146       0.02          school   \n",
       "2           2      1205        0.02     1008       0.02           water   \n",
       "12         12      1015        0.02     1529       0.02          report   \n",
       "7           7       910        0.01     1270       0.02        military   \n",
       "11         11       894        0.01     1064       0.02           women   \n",
       "8           8       879        0.01      921       0.01            vote   \n",
       "0           0       843        0.01      979       0.02            drug   \n",
       "33         33       770        0.01     1733       0.03         percent   \n",
       "1           1       732        0.01      802       0.01        veterans   \n",
       "29         29       727        0.01      536       0.01          energy   \n",
       "28         28       654        0.01      918       0.01            bank   \n",
       "19         19       593        0.01      748       0.01       emergency   \n",
       "3           3       544        0.01     1112       0.02            vote   \n",
       "22         22       533        0.01      710       0.01           trade   \n",
       "30         30       481        0.01      746       0.01        research   \n",
       "17         17       407        0.01      654       0.01        children   \n",
       "25         25       336        0.01      553       0.01  transportation   \n",
       "14         14       209        0.00      380       0.01            farm   \n",
       "6           6       135        0.00      365       0.01            fire   \n",
       "31         31        79        0.00      433       0.01           state   \n",
       "\n",
       "            kw1            kw2           kw3                    kw4  \\\n",
       "26         want           come          know                    get   \n",
       "18     chairman      gentleman     committee                  offer   \n",
       "9     committee     resolution          rule  ask_unanimous_consent   \n",
       "16          act      provision       require               congress   \n",
       "24      service         family         honor                     dr   \n",
       "13      service       national     recognize                  award   \n",
       "35        great         nation           day               american   \n",
       "4         money           want          know                   dont   \n",
       "32        spend        billion           cut                deficit   \n",
       "20         fund        provide       million                  house   \n",
       "27      nations  international        policy              countries   \n",
       "10        peace        freedom        israel                   must   \n",
       "5         right          court          case           constitution   \n",
       "34          pay       medicare       benefit                   plan   \n",
       "23       health          child       disease              treatment   \n",
       "15      workers        economy         labor                 create   \n",
       "21    education       students       college               children   \n",
       "2          land  environmental        forest                project   \n",
       "12  information     department  intelligence             government   \n",
       "7           war           iraq         troop                defense   \n",
       "11      medical           care        health                 doctor   \n",
       "8         judge     nomination      senators               district   \n",
       "0         crime         border   immigration                    gun   \n",
       "33         cost       increase       million                   year   \n",
       "1       service          serve            va               military   \n",
       "29          oil          price          fuel             production   \n",
       "28         loan      financial        credit         small_business   \n",
       "19         home           help         texas                  state   \n",
       "3      congress      political    republican                 public   \n",
       "22      company       industry        market               american   \n",
       "30   technology            new       science                  space   \n",
       "17      program       families       welfare                  child   \n",
       "25       safety        project        system                highway   \n",
       "14      farmers    agriculture          food           agricultural   \n",
       "6          ship           port          navy                  haiti   \n",
       "31   washington       colorado    california                 alaska   \n",
       "\n",
       "                kw5          kw6             kw7               kw8  \\\n",
       "26            issue         talk             way               see   \n",
       "18             vote         want      amendments             thank   \n",
       "9            follow        order             may              hear   \n",
       "16          federal      provide         process           section   \n",
       "24           member         life          career        university   \n",
       "13      association       center            city             honor   \n",
       "35             live        first           world         americans   \n",
       "4              tell         back            come               let   \n",
       "32         congress         debt            year               tax   \n",
       "20          service      include      assistance           federal   \n",
       "27          nuclear         must  administration         agreement   \n",
       "10           soviet    democracy          jewish          continue   \n",
       "5    constitutional        judge           legal           federal   \n",
       "34  social_security       income            cost         insurance   \n",
       "23             live       parent        national          research   \n",
       "15         economic     american       employees         americans   \n",
       "21          program  educational        teachers             young   \n",
       "2          national       public            area       environment   \n",
       "12       commission       office       committee    administration   \n",
       "7             force         army         soldier       afghanistan   \n",
       "11         patients     hospital        abortion           service   \n",
       "8            record      present              ms           confirm   \n",
       "0          violence          act          mexico   law_enforcement   \n",
       "33           number      billion            rate              less   \n",
       "1             honor    men_women         country          families   \n",
       "29            power  natural_gas             use            supply   \n",
       "28           market     business         company  small_businesses   \n",
       "19          florida        flood        disaster            damage   \n",
       "3             party   democratic           house          campaign   \n",
       "22           export      foreign        products         countries   \n",
       "30          program         test          system          national   \n",
       "17             poor       family         poverty              live   \n",
       "25     construction          air           build           airport   \n",
       "14          program        price           rural          arkansas   \n",
       "6              flag  coast_guard         officer              guam   \n",
       "31           indian    minnesota          nevada          governor   \n",
       "\n",
       "                  kw9  \n",
       "26            country  \n",
       "18        distinguish  \n",
       "9             members  \n",
       "16             change  \n",
       "24               john  \n",
       "13               year  \n",
       "35               life  \n",
       "4                 pay  \n",
       "32               vote  \n",
       "20              grant  \n",
       "27           security  \n",
       "10              world  \n",
       "5       supreme_court  \n",
       "34            seniors  \n",
       "23               help  \n",
       "15               help  \n",
       "21              learn  \n",
       "2                park  \n",
       "12           security  \n",
       "7             general  \n",
       "11             access  \n",
       "8   district_columbia  \n",
       "0             victims  \n",
       "33              level  \n",
       "1           sacrifice  \n",
       "29                gas  \n",
       "28            capital  \n",
       "19        communities  \n",
       "3            election  \n",
       "22             import  \n",
       "30                use  \n",
       "17               care  \n",
       "25              truck  \n",
       "14             market  \n",
       "6               beach  \n",
       "31             native  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics_df_joined.sort_values(by='Prim_Cnt', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
