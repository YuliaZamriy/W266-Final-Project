{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 6.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting chardet<3.1.0,>=3.0.2 (from requests)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |████████████████████████████████| 143kB 16.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17 (from requests)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9f/e0/accfc1b56b57e9750eba272e24c4dddeac86852c2bebd1236674d7887e8a/certifi-2018.11.29-py2.py3-none-any.whl (154kB)\n",
      "\u001b[K    100% |████████████████████████████████| 163kB 45.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.25,>=1.21.1 (from requests)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/00/ee1d7de624db8ba7090d1226aebefab96a2c71cd5cfa7629d6ad3f61b79e/urllib3-1.24.1-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |████████████████████████████████| 122kB 55.6MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna<2.9,>=2.5 (from requests)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 24.8MB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: chardet, certifi, urllib3, idna, requests\n",
      "Successfully installed certifi-2018.11.29 chardet-3.0.4 idna-2.8 requests-2.21.0 urllib3-1.24.1\n"
     ]
    }
   ],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape(url):\n",
    "    page_response = requests.get(url, timeout=5)\n",
    "    return BeautifulSoup(page_response.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## African American House of Representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = scrape('https://en.wikipedia.org/wiki/List_of_African-American_United_States_Representatives')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is stored between td tags\n",
    "allrows = page_content.find_all(\"td\")\n",
    "black_h, new = [], []\n",
    "for i in range(len(allrows)):\n",
    "    # rows with b tag have names\n",
    "    if allrows[i].find('b'):\n",
    "        if new:\n",
    "            black_h.append(new)\n",
    "            new = []\n",
    "        if allrows[i].find('a'):\n",
    "            # names are within a tag\n",
    "            if allrows[i].find('a').get('title'):\n",
    "                # extract name\n",
    "                new.append(allrows[i].find('a')['title'])\n",
    "    # rows with br tag have years\n",
    "    elif allrows[i].find('br'):\n",
    "        if allrows[i].find('span'):\n",
    "            # years in congress\n",
    "            new.append(allrows[i].find('span').text)\n",
    "black_h.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "155"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(black_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out name and first-last years in congress\n",
    "with open(\"ethicity_black.txt\", \"w\") as f:\n",
    "    for p in black_h:\n",
    "        name = p[0].upper()\n",
    "        start_year = p[1:][0][1:5]\n",
    "        end_year = p[1:][-1][-5:-1]\n",
    "        f.write(name+\"\\t\"+start_year+\"\\t\"+end_year+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hispanics and Latino Congresspeople"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = scrape('https://en.wikipedia.org/wiki/List_of_Hispanic_and_Latino_Americans_in_the_United_States_Congress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is stored between td tags\n",
    "allrows = page_content.find_all(\"td\")\n",
    "hispanic_sh, new = [], []\n",
    "for i in range(len(allrows)):\n",
    "    # rows with b tag have names\n",
    "    if allrows[i].find('b'):\n",
    "        if new:\n",
    "            hispanic_sh.append(new)\n",
    "            new = []\n",
    "        if allrows[i].find('a'):\n",
    "            # names are within a tag\n",
    "            if allrows[i].find('a').get('title'):\n",
    "                new.append(allrows[i].find('a')['title'])\n",
    "    elif allrows[i].find('span'):\n",
    "        # getting to the years in congress\n",
    "        if allrows[i].find('span').get('data-sort-value'):\n",
    "            new.append(allrows[i].find('span').text)\n",
    "hispanic_sh.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hispanic_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out name and first-last years in congress\n",
    "with open(\"ethicity_hispanic.txt\", \"w\") as f:\n",
    "    for p in hispanic_sh:\n",
    "        # first row has junk data\n",
    "        if len(p) > 1:\n",
    "            name = p[0].upper()\n",
    "            start_year = p[1:][0][-4:]\n",
    "            end_year = p[1:][-1][-4:]\n",
    "            f.write(name+\"\\t\"+start_year+\"\\t\"+end_year+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asian American and Pacific Islands American Congresspeople"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = scrape('https://en.wikipedia.org/wiki/List_of_Asian_Americans_and_Pacific_Islands_Americans_in_the_United_States_Congress')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data is stored between td tags\n",
    "allrows = page_content.find_all(\"td\")\n",
    "aapia_sh, new = [], []\n",
    "for i in range(len(allrows)):\n",
    "    # rows with b tag have names\n",
    "    if allrows[i].find('b'):\n",
    "        if new:\n",
    "            aapia_sh.append(new)\n",
    "            new = []\n",
    "        if allrows[i].find('a'):\n",
    "            # names are within a tag\n",
    "            if allrows[i].find('a').get('title'):\n",
    "                new.append(allrows[i].find('a')['title'])\n",
    "    elif allrows[i].find('span'):\n",
    "        # getting to the years in congress\n",
    "        if allrows[i].find('span').get('data-sort-value'):\n",
    "            new.append(allrows[i].find('span').text)\n",
    "aapia_sh.append(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aapia_sh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out name and first-last years in congress\n",
    "with open(\"ethicity_aapia.txt\", \"w\") as f:\n",
    "    for p in aapia_sh:\n",
    "        # first row has junk data\n",
    "        if len(p) > 1:\n",
    "            name = p[0].upper()\n",
    "            start_year = p[1:][0][-4:]\n",
    "            end_year = p[1:][-1][-4:]\n",
    "            f.write(name+\"\\t\"+start_year+\"\\t\"+end_year+\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age for 97-114 Congresspeople"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = scrape('https://www.congress.gov/members?q=%7B%22congress%22%3A%5B%22114%22%2C%22113%22%2C%22112%22%2C%22111%22%2C%22110%22%2C%22109%22%2C%22108%22%2C%22107%22%2C%22106%22%2C%22105%22%2C%22104%22%2C%22103%22%2C%22102%22%2C%22101%22%2C%22100%22%2C%2299%22%2C%2298%22%2C%2297%22%5D%7D&page=1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this page has all congresspeople filtered for 97-114 congresses\n",
    "url = 'https://www.congress.gov/members?q=%7B%22congress%22%3A%5B%22114%22%2C%22113%22%2C%22112%22%2C%22111%22%2C%22110%22%2C%22109%22%2C%22108%22%2C%22107%22%2C%22106%22%2C%22105%22%2C%22104%22%2C%22103%22%2C%22102%22%2C%22101%22%2C%22100%22%2C%2299%22%2C%2298%22%2C%2297%22%5D%7D&page='\n",
    "bios = {}\n",
    "for i in range(1,20):\n",
    "    page = scrape(url+str(i))\n",
    "    allrows = page.find_all(\"li\", class_=\"compact\")\n",
    "    for p in allrows:\n",
    "        name = p.find('a').text\n",
    "        # remove Senator/Representative from the front of the name\n",
    "        if name[0] == 'S':\n",
    "            name = p.find('a').text[8:]\n",
    "        elif name[0] == 'R':\n",
    "            name = p.find('a').text[15:]\n",
    "        # get the id\n",
    "        bios[name]=p.find('a')['href'][-7:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1807"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(bios.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if you names\n",
    "check = {'Guinta, Frank C.': 'G000570',\n",
    " 'Engel, Eliot L.': 'E000179',\n",
    " 'Kind, Ron': 'K000188',\n",
    " 'Sweeney, David McCann': 'S001101',\n",
    " 'Gibbons, Sam': 'G000153',\n",
    " 'Bliley, Tom': 'B000556',\n",
    " 'Sasse, Ben ': 'S001197',\n",
    " 'Swalwell, Eric': 'S001193'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this page contains bio information for all the congresspeople\n",
    "url = 'http://bioguide.congress.gov/scripts/biodisplay.pl?index='\n",
    "bios2 = {}\n",
    "for p in bios:\n",
    "    page = scrape(url+bios[p])\n",
    "    allrows = page.find_all('td')\n",
    "    for r in allrows:\n",
    "        if len(r.find_all('font')) > 1:\n",
    "            # extract birthyear\n",
    "            birthyear = r.find_all('font')[1].text.strip()[1:5]\n",
    "            bios2[p.upper()] = birthyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1807"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(bios2.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"congresspeople_age.txt\", \"w\") as f:\n",
    "    for p in bios2:\n",
    "        f.write(p+\"\\t\"+bios2[p]+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"congresspeople_id.txt\", \"w\") as f:\n",
    "    for p in bios:\n",
    "        f.write(p.upper()+\"\\t\"+bios[p]+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
